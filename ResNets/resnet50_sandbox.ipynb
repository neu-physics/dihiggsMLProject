{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Add, Dense, ZeroPadding2D, Activation, BatchNormalization, \\\n",
    "    Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# TODO: kernal initalizer?\n",
    "# TODO: average pooling instead of max pooling for final layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Resnet architecture ----- # \n",
    "\n",
    "def identity_block(X, filters, kernel_size):\n",
    "    '''\n",
    "    residual block with 3 skips\n",
    "\n",
    "    X - input tensor\n",
    "    filters - number of filters in the convolutional layer\n",
    "    kernel_size - dimension of square filter to go over image\n",
    "    stage - way to label position of block in network\n",
    "    '''\n",
    "\n",
    "    f1, f2, f3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First block\n",
    "    X = Conv2D(filters=f1, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(filters=f2, kernel_size=(kernel_size,kernel_size), strides=(1,1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third Block\n",
    "    X = Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    # Add shortcut Block\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def conv_block(X, filters, kernel_size, strides=2):\n",
    "    '''\n",
    "\n",
    "    residual block with 3 skips, the \"shortcut\" path has a conv layer\n",
    "\n",
    "    X - input tensor of shape (h_previous, w_previous, c_previous)\n",
    "    filters - number of filters in the conv layer\n",
    "    kernel_size - dimension of square filter to go over image\n",
    "    strides - how big of a translation the filters taken when going through image\n",
    "\n",
    "    returns: tensor of shape (h,w,c)\n",
    "    '''\n",
    "\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First Block\n",
    "    X = Conv2D(filters= f1, kernel_size=(1,1), strides=(strides,strides), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(filters=f2, kernel_size=(kernel_size,kernel_size), strides=(1,1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third Block\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "\n",
    "    # Conv Shortcut and Adding\n",
    "    X_shortcut = Conv2D(filters= f3, kernel_size=(1,1), strides=(strides,strides), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def resnet_50(input_shape = (244, 244, 3), classes = 2):\n",
    "\n",
    "    '''\n",
    "    input_shape - dimensions of the image - (img_height, img_width, channels)\n",
    "    '''\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "    # Initial Convolution Block\n",
    "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((1, 1), strides=(1, 1))(X)\n",
    "\n",
    "    # First Block\n",
    "    X = conv_block(X, filters=[64, 64, 256], kernel_size=3, strides=1)\n",
    "    X = identity_block(X, filters=[64, 64, 256], kernel_size=3)\n",
    "    X = identity_block(X, filters=[64, 64, 256], kernel_size=3)\n",
    "\n",
    "    # Second Block\n",
    "    X = conv_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "\n",
    "    # Third Block\n",
    "    X = conv_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "\n",
    "    # Fourth Block\n",
    "    X = conv_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "    X = identity_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "    X = identity_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "\n",
    "    X = AveragePooling2D((1,1))(X)\n",
    "\n",
    "    # Flatten and create model\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs= X_input, outputs = X, name= \"ResNet50\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Functions for plotting training, and testing with different data sets ---- # \n",
    "\n",
    "def plot_training_history(hist):\n",
    "    '''\n",
    "    hist: keras model history from training - model.fit()\n",
    "    '''\n",
    "    \n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.title('Model accuracy and loss')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Accuracy', 'Loss'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def test_with_data(data_file, model, image_size, channels):\n",
    "    test_data = np.genfromtxt(data_file, delimiter=\",\")\n",
    "    test_X = test_data[:, :3]\n",
    "    test_y = test_data[:, -1]\n",
    "\n",
    "    test_y = to_categorical(test_y)\n",
    "\n",
    "    X = np.reshape(test_X, (test_X.shape[0], 1, 1, test_X.shape[1]))\n",
    "    train_zeros = np.zeros((test_X.shape[0], inner, inner, test_X.shape[1]))\n",
    "    X = X + train_zeros\n",
    "\n",
    "    preds = model.evaluate(X, test_y)\n",
    "    print(\"Loss = \", preds[0])\n",
    "    print(\"Test Accuracy = \", preds[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 2550\n",
      "number of test examples = 850\n",
      "X_train shape: (2550, 1, 1, 16)\n",
      "Y_train shape: (2550, 2)\n",
      "X_test shape: (850, 1, 1, 16)\n",
      "Y_test shape: (850, 2)\n",
      "Epoch 1/2\n",
      "2550/2550 [==============================] - 167s 66ms/step - loss: 0.9086 - acc: 0.8318\n",
      "Epoch 2/2\n",
      "2550/2550 [==============================] - 142s 55ms/step - loss: 0.0949 - acc: 0.9706\n",
      "850/850 [==============================] - 3s 3ms/step\n",
      "Loss =  0.05737373981843977\n",
      "Test Accuracy =  0.9788235294117648\n"
     ]
    }
   ],
   "source": [
    "image_size = 1\n",
    "channels   = 16\n",
    "\n",
    "data = np.genfromtxt(\"SimpleDataSet.csv\", delimiter=\",\")\n",
    "y    = data[:,-1]\n",
    "X    = data[:,:channels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)\n",
    "\n",
    "\n",
    "# one hot encoding for labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "# change input dimensions so it has 4 dimensions instead of 2\n",
    "X_train     = np.reshape(X_train, (X_train.shape[0],1,1,X_train.shape[1]))\n",
    "X_test      = np.reshape(X_test,   (X_test.shape[0],1,1,X_test.shape[1]))\n",
    "\n",
    "train_zeros = np.zeros((X_train.shape[0],image_size,image_size,X_train.shape[1]))\n",
    "test_zeros  = np.zeros(( X_test.shape[0],image_size,image_size,X_test.shape[1]))\n",
    "\n",
    "X_train     = X_train + train_zeros\n",
    "X_test      = X_test + test_zeros\n",
    "\n",
    "# X dimensions: (num_samples, img_size, img_size, channels) \n",
    "# Y dimensions: (num_samples, num_classes)\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \"     + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \"                + str(X_train.shape))\n",
    "print(\"Y_train shape: \"                + str(y_train.shape))\n",
    "print(\"X_test shape: \"                 + str(X_test.shape))\n",
    "print(\"Y_test shape: \"                 + str(y_test.shape))\n",
    "\n",
    "# create model\n",
    "model = resnet_50(input_shape=(image_size,image_size,channels), classes=2)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# fit model to data, evaluate it against testing data\n",
    "history = model.fit(X_train, y_train, epochs=2, batch_size=32)\n",
    "preds   = model.evaluate(X_test, y_test)\n",
    "print(\"Loss = \",          preds[0])\n",
    "print(\"Test Accuracy = \", preds[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_model = resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "# true_model.load_weights('resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "# true_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "# preds = true_model.predict(X_test)\n",
    "# print(preds)\n",
    "# print(\"\\n-----------\\n\")\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# # Ways to test the identity block and conv block code\n",
    "#\n",
    "# tf.reset_default_graph()\n",
    "#\n",
    "# with tf.Session() as test:\n",
    "#     np.random.seed(1)\n",
    "#     A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "#     X = np.random.randn(3, 4, 4, 6)\n",
    "#     A = conv_block(A_prev, filters=[2, 4, 6], kernel_size=2)\n",
    "#     A = identity_block(A_prev, filters=[2, 4, 6], kernel_size=2)\n",
    "#     test.run(tf.global_variables_initializer())\n",
    "#     out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "#     print(\"out = \" + str(out[0][1][1][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
