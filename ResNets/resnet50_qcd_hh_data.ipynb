{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Add, Dense, ZeroPadding2D, Activation, BatchNormalization, \\\n",
    "    Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# TODO: kernal initalizer?\n",
    "# TODO: average pooling instead of max pooling for final layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Resnet architecture ######## \n",
    "\n",
    "def identity_block(X, filters, kernel_size):\n",
    "    '''\n",
    "    residual block with 3 skips\n",
    "\n",
    "    X - input tensor\n",
    "    filters - number of filters in the convolutional layer\n",
    "    kernel_size - dimension of square filter to go over image\n",
    "    stage - way to label position of block in network\n",
    "    '''\n",
    "\n",
    "    f1, f2, f3 = filters\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First block\n",
    "    X = Conv2D(filters=f1, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(filters=f2, kernel_size=(kernel_size,kernel_size), strides=(1,1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third Block\n",
    "    X = Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    # Add shortcut Block\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def conv_block(X, filters, kernel_size, strides=2):\n",
    "    '''\n",
    "\n",
    "    residual block with 3 skips, the \"shortcut\" path has a conv layer\n",
    "\n",
    "    X - input tensor of shape (h_previous, w_previous, c_previous)\n",
    "    filters - number of filters in the conv layer\n",
    "    kernel_size - dimension of square filter to go over image\n",
    "    strides - how big of a translation the filters taken when going through image\n",
    "\n",
    "    returns: tensor of shape (height,width,channels)\n",
    "    '''\n",
    "\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First Block\n",
    "    X = Conv2D(filters= f1, kernel_size=(1,1), strides=(strides,strides), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(filters=f2, kernel_size=(kernel_size,kernel_size), strides=(1,1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third Block\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "\n",
    "    # Conv Shortcut and Adding\n",
    "    X_shortcut = Conv2D(filters= f3, kernel_size=(1,1), strides=(strides,strides), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def resnet_50(input_shape = (244, 244, 3), classes = 2):\n",
    "\n",
    "    '''\n",
    "    input_shape - dimensions of the image - (img_height, img_width, channels)\n",
    "    '''\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "\n",
    "    # Initial Convolution Block\n",
    "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((1, 1), strides=(1, 1))(X)\n",
    "\n",
    "    # First Block\n",
    "    X = conv_block(X, filters=[64, 64, 256], kernel_size=3, strides=1)\n",
    "    X = identity_block(X, filters=[64, 64, 256], kernel_size=3)\n",
    "    X = identity_block(X, filters=[64, 64, 256], kernel_size=3)\n",
    "\n",
    "    # Second Block\n",
    "    X = conv_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "    X = identity_block(X, filters=[128, 128, 512], kernel_size=3)\n",
    "\n",
    "    # Third Block\n",
    "    X = conv_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "    X = identity_block(X, filters=[256, 256, 1024], kernel_size=3)\n",
    "\n",
    "    # Fourth Block\n",
    "    X = conv_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "    X = identity_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "    X = identity_block(X, filters=[512, 512, 2048], kernel_size=3)\n",
    "\n",
    "    X = AveragePooling2D((1,1))(X)\n",
    "\n",
    "    # Flatten and create model\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs= X_input, outputs = X, name= \"ResNet50\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(hist):\n",
    "    '''\n",
    "    hist: keras model history from training - model.fit()\n",
    "    '''\n",
    "    \n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.title('Model accuracy and loss')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Accuracy', 'Loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 4731\n",
      "number of test examples = 1577\n",
      "X_train shape: (4731, 3, 3, 1)\n",
      "Y_train shape: (4731, 2)\n",
      "X_test shape: (1577, 3, 3, 1)\n",
      "Y_test shape: (1577, 2)\n",
      "Epoch 1/3\n",
      "2656/4731 [===============>..............] - ETA: 2:15 - loss: 1.5641 - acc: 0.6724"
     ]
    }
   ],
   "source": [
    "image_rows = 3\n",
    "image_cols = 3\n",
    "\n",
    "channels   = 1\n",
    "\n",
    "# print(\"LOADING DATA....\")\n",
    "\n",
    "qcd_data_original = np.genfromtxt(\"qcd_outputDataForLearning.csv\", skip_header=1, delimiter=\",\")\n",
    "hh_data_original  = np.genfromtxt(\"dihiggs_outputDataForLearning.csv\", skip_header=1, delimiter=\",\")\n",
    "\n",
    "# adding easily seperable column\n",
    "# hh all positive, qcd all negative, uniform dist [0,1]\n",
    "n_points = 1  # per event\n",
    "hh_fake = np.random.rand(len(hh_data_original), n_points) \n",
    "qcd_fake = np.random.rand(len(qcd_data_original), n_points)\n",
    "\n",
    "hh_fake = np.abs(hh_fake)\n",
    "qcd_fake = np.abs(qcd_fake)\n",
    "\n",
    "hh_fake = hh_fake * (1/np.max(hh_fake))\n",
    "qcd_fake = -qcd_fake * (1/np.max(qcd_fake))\n",
    "\n",
    "# add fake column(s) to real data\n",
    "hh_data_original = np.append(hh_data_original, hh_fake, axis=1)\n",
    "qcd_data_original = np.append(qcd_data_original, qcd_fake, axis=1)\n",
    "\n",
    "# generate labels for hh and qcd\n",
    "hh_labels= np.ones((len(hh_data_original),1))\n",
    "hh_data_original = np.append(hh_data_original, hh_labels, axis=1)\n",
    "\n",
    "qcd_labels= np.zeros((len(qcd_data_original),1))\n",
    "qcd_data_original = np.append(qcd_data_original, qcd_labels, axis=1)\n",
    "\n",
    "# add all data together\n",
    "all_data_original = np.append(hh_data_original, qcd_data_original, axis=0)\n",
    "\n",
    "\n",
    "# list of columns to include from qcd/dihiggs data:\n",
    "#\n",
    "# hh_mass h1_mass h2_mass hh_pt h1_pt h2_pt deltaR(h1, h2) deltaR(h1 jets) deltaR(h2 jets)\n",
    "#  0        1       2       3     4     5     6              7               8\n",
    "# deltaPhi(h1, h2) deltaPhi(h1 jets) deltaPhi(h2 jets) met met_phi scalarHT nJets nBTags isMatchable\n",
    "#     9                 10              11             12    13       14     15    16       17\n",
    "# jet1_pt jet2_pt jet3_pt jet4_pt jet1_eta jet2_eta jet3_eta jet4_eta jet1_phi jet2_phi jet3_phi jet4_phi\n",
    "#  18      19       20       21      22       23       24       25        26      27       28       29\n",
    "# jet1_mass jet2_mass jet3_mass jet4_mass jet1_px jet2_px jet3_px jet4_px jet1_py jet2_py jet3_py jet4_py \n",
    "#     30        31        32        33        34      35      36      37      38      39      40      41\n",
    "# jet1_pz jet2_pz jet3_pz jet4_pz jet1_energy jet2_energy jet3_energy jet4_energy \n",
    "#     42      43      44      45      46          47          48          49\n",
    "# jet1_btag jet2_btag jet3_btag jet4_btag fake_column LABEL\n",
    "#     50        51        52        53        54       55\n",
    "\n",
    "iteration = [0, 1, 2, 6, 7, 8, 9, 10, 11, 55]\n",
    "\n",
    "all_data = all_data_original[:,iteration]\n",
    "\n",
    "for i in range(4):\n",
    "    np.random.shuffle(all_data)\n",
    "\n",
    "y    = all_data[:,-1]\n",
    "X    = all_data[:,:-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=9)\n",
    "\n",
    "# one hot encoding for labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    "\n",
    "# change input dimensions so it has 4 dimensions instead of 2\n",
    "X_train     = np.reshape(X_train, (X_train.shape[0],image_rows,image_cols,channels))\n",
    "X_test      = np.reshape(X_test,   (X_test.shape[0],image_rows,image_cols,channels))\n",
    "\n",
    "\n",
    "# X dimensions: (num_samples, img_size, img_size, channels) \n",
    "# Y dimensions: (num_samples, num_classes)\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \"     + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \"                + str(X_train.shape))\n",
    "print(\"Y_train shape: \"                + str(y_train.shape))\n",
    "print(\"X_test shape:  \"                 + str(X_test.shape))\n",
    "print(\"Y_test shape:  \"                 + str(y_test.shape))\n",
    "\n",
    "\n",
    "# print(\"CREATING AND COMPILING RESNET MODEL....\")\n",
    "\n",
    "\n",
    "# create model\n",
    "model = resnet_50(input_shape=(image_rows,image_cols,channels), classes=2)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#print(\"BEGINNING MODEL TRAINING....\")\n",
    "\n",
    "\n",
    "# fit model to data, evaluate it against testing data\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "preds   = model.evaluate(X_test, y_test)\n",
    "print(\"Loss = \",          preds[0])\n",
    "print(\"Test Accuracy = \", preds[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
