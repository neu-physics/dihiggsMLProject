{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do\n",
    "# 1) plot some variables before and after normalization. how do they compare?\n",
    "# X) try batch normalization in the network? re-do step1 maybe?\n",
    "# 3) to_categorical for signal and background preds?\n",
    "# 4) grid optimization? --> dropout rate, layers, nodes, etc\n",
    "# X) k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.utils import normalize, to_categorical\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.models import load_model\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n",
    "from lbn import LBN, LBNLayer\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '/home/btannenw/Desktop/ML/dihiggsMLProject/')\n",
    "from utils.commonFunctions import *\n",
    "\n",
    "#model_dir = os.path.join(tut.data_dir, \"lbn\", \"models\", name)\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dihiggs file:  /home/btannenw/Desktop/ML/dihiggsMLProject/data/pp2hh4b_500kEvents_0PU_v2-05__top4inPt-4tags-10jets_combined_csv.csv\n",
      "QCD file:  /home/btannenw/Desktop/ML/dihiggsMLProject/data/ppTo4b_2MEvents_0PU_v2-05__top4inPt-4tags-10jets_combined_csv.csv\n"
     ]
    }
   ],
   "source": [
    "#*** 1. Import data and check stuff\n",
    "testingFraction = 0.3\n",
    "\n",
    "# *** A. Import Dataset\n",
    "hh_raw, qcd_raw = importDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.3195e+04, 4.0870e+04, 2.5949e+04, 1.1225e+04, 3.8130e+03,\n",
       "        1.1030e+03, 2.6100e+02, 5.6000e+01, 5.0000e+00, 4.0000e+00]),\n",
       " array([ 4. ,  4.9,  5.8,  6.7,  7.6,  8.5,  9.4, 10.3, 11.2, 12.1, 13. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(qcd_raw.nJets, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_sig = 78876 , N_bkg = 116481\n",
      "195357 rows of total data with  195357 labels [Train+Test]\n",
      "136749 rows of training data with  136749 labels [Train]\n",
      "58608 rows of testing data with  58608 labels [Test]\n"
     ]
    }
   ],
   "source": [
    "# *** 2. Make mix of dihiggs and QCD for specified variables\n",
    "jetLabels = ['1','2','3','4','5','6','7','8']\n",
    "jetVariables = ['energy', 'px', 'py', 'pz']\n",
    "variables_jetVects = ['jet{0}_{1}'.format(iJetLabel, iJetVariable) for iJetLabel in jetLabels for iJetVariable in jetVariables]\n",
    "\n",
    "# *** 2. Split testing and training\n",
    "jetVects_data_train, jetVects_data_test, jetVects_labels_train, jetVects_labels_test = makeTestTrainSamplesWithUserVariables(hh_raw, qcd_raw, variables_jetVects, testingFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136749, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** 2. Create jet vector inputs\n",
    "def returnJetVectorInputsToLBN(_df, _jetType='jet', _nJets=4):\n",
    "    \n",
    "    #flattened\n",
    "    _allVectorsFlattened = None\n",
    "    _var = [_jetType+'{}_energy', _jetType+'{}_px', _jetType+'{}_py', _jetType+'{}_pz']\n",
    "    \n",
    "    for i in range(1, _nJets + 1):\n",
    "        _varN = [x.format(i) for x in _var]\n",
    "        _jetNData = _df[ _varN ].astype(np.float32)\n",
    "        _vectN = [list(x) for x in _jetNData.values]\n",
    "        \n",
    "        if _allVectorsFlattened == None:\n",
    "            _allVectorsFlattened = _vectN\n",
    "        else:\n",
    "            _allVectorsFlattened = [ x + y for x,y in zip(_allVectorsFlattened, _vectN) ]\n",
    "\n",
    "    return np.array(_allVectorsFlattened)\n",
    "    \n",
    "\n",
    "nJets = 8\n",
    "jetType = 'jet'\n",
    "trainVectorsByEvent = returnJetVectorInputsToLBN( jetVects_data_train, jetType, nJets)\n",
    "testVectorsByEvent  = returnJetVectorInputsToLBN( jetVects_data_test, jetType, nJets)\n",
    "\n",
    "trainLabelsByEvent = np.array([[0.,1.] if x ==0 else [1.,0.] for x in jetVects_labels_train.isSignal]).astype(np.float32)\n",
    "testLabelsByEvent  = np.array([[0.,1.] if x ==0 else [1.,0.] for x in jetVects_labels_test.isSignal]).astype(np.float32)\n",
    "\n",
    "#np.array(jetVects_labels_train)\n",
    "np.shape(trainVectorsByEvent)\n",
    "#np.array(trainLabelsByEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 3A. Define LBN model and train\n",
    "def createModelLBN(_nodesInFirstHiddenLayer=80, _nodesInSecondHiddenLayer=256, _hiddenActivation='relu', _outputActivation='sigmoid', _weightsFile=''):\n",
    "    \"\"\"make lbn model\"\"\"\n",
    "    #init = tf.keras.initializers.RandomNormal(mean=0., stddev=0.1, seed=123)\n",
    " \n",
    "    features = [\"E\", \"pt\", \"eta\", \"phi\", \"m\", \"pair_dr\"]\n",
    "    lbn_layer = LBNLayer(n_particles=5, boost_mode=\"pairs\", features=features)\n",
    "    \n",
    "    \n",
    "    metrics = [\n",
    "        tf.keras.metrics.categorical_accuracy,\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    \n",
    "    #l2_reg = l2(1e-4)\n",
    "    \n",
    "    l2_reg = tf.keras.regularizers.l2(1e-4)\n",
    "    \n",
    "    dense_kwargs_IML = dict(\n",
    "        activation=\"selu\",\n",
    "        kernel_initializer=tf.keras.initializers.lecun_normal(),\n",
    "        kernel_regularizer=l2_reg,\n",
    "    )\n",
    "\n",
    "    dense_kwargs = dict(\n",
    "        activation=_hiddenActivation,\n",
    "        kernel_initializer=tf.keras.initializers.lecun_normal(),\n",
    "        kernel_regularizer=l2_reg,\n",
    "    )\n",
    "\n",
    "    _model = tf.keras.models.Sequential()\n",
    "\n",
    "    #_model.add(LBNLayer(5, boost_mode=LBN.PAIRS, features=features))\n",
    "    _model.add(lbn_layer)\n",
    "    _model.add(tf.keras.layers.BatchNormalization(axis=1))\n",
    "\n",
    "\n",
    "    _model.add(tf.keras.layers.Dense(80, **dense_kwargs))#, kernel_regularizer=l2_reg))\n",
    "    _model.add(tf.keras.layers.Dense(256, **dense_kwargs))#, kernel_regularizer=l2_reg))\n",
    "\n",
    "\n",
    "    #_model.add(tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=init))\n",
    "    #_model.add(tf.keras.layers.Dense(750, activation='relu'))#, kernel_regularizer=l2_reg))\n",
    "    #_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dropout(0.2))\n",
    "    #_model.add(BatchNormalization())\n",
    "\n",
    "    #_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    _model.add(tf.keras.layers.Dense(2, activation=_outputActivation, kernel_regularizer=l2_reg))\n",
    "        \n",
    "    _model.compile(loss='binary_crossentropy',\n",
    "                  #loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  #metrics=['accuracy']\n",
    "                  metrics = metrics\n",
    "                 )\n",
    "\n",
    "    #print(_model.weights)\n",
    "    \n",
    "    if _weightsFile !='':\n",
    "        _model = _model.get_weights(_weightsFile)\n",
    "        for _layer in _model.layers:\n",
    "            _layer.trainable_ = False\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, name, data=None, validation_data=None, epochs=10, batch_size=512):\n",
    "    topDir = '/home/btannenw/Desktop/ML/dihiggsMLProject/lorentzBoostNetwork/'\n",
    "    \n",
    "    model_dir = os.path.join(topDir, \"lbn\", \"models\", name)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    fit_callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(model_dir, name),\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            monitor=\"val_auc\",\n",
    "            mode=\"max\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    if data is None:\n",
    "        data = (trainVectorsByEvent, trainLabelsByEvent)\n",
    "    if validation_data is None:\n",
    "        validation_data = (testVectorsByEvent, testLabelsByEvent)\n",
    "\n",
    "    model.fit(data[0], data[1],\n",
    "        validation_data=validation_data,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=fit_callbacks,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(model, name):\n",
    "    topDir = '/home/btannenw/Desktop/ML/dihiggsMLProject/lorentzBoostNetwork/'\n",
    "\n",
    "    local_dir = os.path.join(topDir, \"lbn\", \"models\", name)\n",
    "    print(\"loading model from {}\".format(local_dir))\n",
    "    model.load_weights(os.path.join(local_dir, name))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136749 samples, validate on 58608 samples\n",
      "Epoch 1/4\n",
      "136749/136749 [==============================] - 7s 50us/sample - loss: 0.6050 - categorical_accuracy: 0.6917 - auc: 0.7656 - val_loss: 0.5703 - val_categorical_accuracy: 0.7151 - val_auc: 0.7975\n",
      "Epoch 2/4\n",
      "136749/136749 [==============================] - 4s 30us/sample - loss: 0.5479 - categorical_accuracy: 0.7340 - auc: 0.8162 - val_loss: 0.5331 - val_categorical_accuracy: 0.7444 - val_auc: 0.8269\n",
      "Epoch 3/4\n",
      "136749/136749 [==============================] - 4s 32us/sample - loss: 0.5256 - categorical_accuracy: 0.7486 - auc: 0.8317 - val_loss: 0.5177 - val_categorical_accuracy: 0.7550 - val_auc: 0.8369\n",
      "Epoch 4/4\n",
      "136749/136749 [==============================] - 4s 31us/sample - loss: 0.5120 - categorical_accuracy: 0.7579 - auc: 0.8407 - val_loss: 0.5092 - val_categorical_accuracy: 0.7595 - val_auc: 0.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f2f9131cf10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t = createModelLBN(_outputActivation='sigmoid') # 1.81+/0.06\n",
    "\n",
    "fit_model(model_t, name='model_t', data=(trainVectorsByEvent, trainLabelsByEvent), \n",
    "          validation_data=(testVectorsByEvent, testLabelsByEvent), epochs=4, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /home/btannenw/Desktop/ML/dihiggsMLProject/lorentzBoostNetwork/lbn/models/model_t.hdf5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_67 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-b37ea1e3cb4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateModelLBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_outputActivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1.81+/0.06\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_t.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-cb5f2782129f>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mlocal_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lbn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading model from {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1168\u001b[0m           \u001b[0;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m           'first, then load the weights.')\n\u001b[0;32m-> 1170\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                        \u001b[0;34m'inputs or `build()` is called with an `input_shape`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m                        self.name)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential_67 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model_t.predict(testVectorsByEvent[5:10])\n",
    "model_t.weights\n",
    "#pred_qcd = model.predict(np.array(qcd_data_test))\n",
    "\n",
    "model_u = createModelLBN(_outputActivation='sigmoid') # 1.81+/0.06\n",
    "\n",
    "load_model(model_u, \"model_t.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136749 samples, validate on 58608 samples\n",
      "Epoch 1/5\n",
      "136749/136749 [==============================] - 10s 75us/sample - loss: 0.5828 - categorical_accuracy: 0.6965 - auc: 0.7752 - val_loss: 0.5461 - val_categorical_accuracy: 0.7271 - val_auc: 0.8094\n",
      "Epoch 2/5\n",
      "136749/136749 [==============================] - 7s 48us/sample - loss: 0.5288 - categorical_accuracy: 0.7414 - auc: 0.8239 - val_loss: 0.5136 - val_categorical_accuracy: 0.7522 - val_auc: 0.8352\n",
      "Epoch 3/5\n",
      "136749/136749 [==============================] - 7s 52us/sample - loss: 0.5022 - categorical_accuracy: 0.7607 - auc: 0.8436 - val_loss: 0.4919 - val_categorical_accuracy: 0.7664 - val_auc: 0.8507\n",
      "Epoch 4/5\n",
      "136749/136749 [==============================] - 7s 50us/sample - loss: 0.4856 - categorical_accuracy: 0.7731 - auc: 0.8553 - val_loss: 0.4779 - val_categorical_accuracy: 0.7748 - val_auc: 0.8600\n",
      "Epoch 5/5\n",
      "136749/136749 [==============================] - 8s 58us/sample - loss: 0.4729 - categorical_accuracy: 0.7814 - auc: 0.8638 - val_loss: 0.4717 - val_categorical_accuracy: 0.7809 - val_auc: 0.8645\n",
      "24350\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=10)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=.001)\n",
    "\n",
    "#mc = ModelCheckpoint('best_model.hdf5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "mc = ModelCheckpoint('best_model.hdf5', #filepath=os.path.join(model_dir, name),\n",
    "                    monitor=\"val_loss\", mode='min', save_weights_only=True, save_best_only=True)\n",
    " \n",
    "\n",
    "#model = createModelLBN(_outputActivation='softmax') # 1.77+/0.04, 1.84 +/- 0.06\n",
    "model = createModelLBN(_outputActivation='sigmoid') # 1.81+/0.06\n",
    "\n",
    "history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=5, validation_data = (testVectorsByEvent, testLabelsByEvent), batch_size=400, callbacks=[es, mc])\n",
    "#history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=10, validation_data = (testVectorsByEvent, testLabelsByEvent))\n",
    "print(model.count_params())\n",
    "\n",
    "# load the saved model\n",
    "#model_best = model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f2e7c969a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# *** 3B. Define low-level NN using jet vectors for comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnInputNodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainVectorsByEvent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.add(Dense(100, input_dim=nInputNodes, activation='relu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# *** 3B. Define low-level NN using jet vectors for comparison\n",
    "model_nn = tf.keras.models.Sequential()\n",
    "nInputNodes = len(trainVectorsByEvent[0]) \n",
    "#model.add(Dense(100, input_dim=nInputNodes, activation='relu'))\n",
    "\n",
    "model_nn.add(tf.keras.layers.Dense(128, input_dim = nInputNodes, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model_nn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model_nn.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_nn.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_nn.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_nn = model_nn.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=50, validation_data = (testVectorsByEvent, testLabelsByEvent), batch_size=400)\n",
    "#history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=10, validation_data = (testVectorsByEvent, testLabelsByEvent))\n",
    "print(model_nn.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_57 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5754ac468bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = model_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mblank_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateModelLBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateModelLBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dummy.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-c78a1f396fe0>\u001b[0m in \u001b[0;36mcreateModelLBN\u001b[0;34m(_nodesInFirstHiddenLayer, _nodesInSecondHiddenLayer, _hiddenActivation, _outputActivation, _weightsFile)\u001b[0m\n\u001b[1;32m     55\u001b[0m                  )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_weightsFile\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_undeduplicated_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;34m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                        \u001b[0;34m'inputs or `build()` is called with an `input_shape`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m                        self.name)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential_57 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "#model = model_best\n",
    "blank_model = createModelLBN()\n",
    "best_model = createModelLBN('best_model.hdf5')\n",
    "\n",
    "model.save_weights('dummy.hdf5', overwrite=True)\n",
    "dumb_model = createModelLBN('dummy.hdf5')\n",
    "\n",
    "#model_best = load_weights('/home/btannenw/Desktop/ML/dihiggsMLProject/lorentzBoostNetork/best_model.h5')\n",
    "print(type(model), type(best_model), type(blank_model))\n",
    "#best_model = model.load_weights('best_model.hdf5')\n",
    "#best_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(type(model), type(best_model), type(dumb_model))\n",
    "\n",
    "\n",
    "\n",
    "dumb_model.predict(testVectorsByEvent[0:10])\n",
    "print(dumb_model.weights)\n",
    "\n",
    "#dumb_model.predict(testVectorsByEvent[5:10])\n",
    "#print(dumb_model.weights)\n",
    "\n",
    "#dumb_model.save_weights('dummy2.hdf5')\n",
    "#print(np.shape(trainVectorsByEvent), np.shape(testVectorsByEvent))\n",
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58608, 2)\n"
     ]
    }
   ],
   "source": [
    "# *** 4. Do some very specific evaluation based on pure samples\n",
    "hh_data_test, hh_labels_test, qcd_data_test, qcd_labels_test = returnTestSamplesSplitIntoSignalAndBackground(testVectorsByEvent, testLabelsByEvent)\n",
    "\n",
    "#score_hh = model.evaluate(np.array(hh_data_test), np.array(hh_labels_test))\n",
    "#score_qcd = model.evaluate(np.array(qcd_data_test), np.array(qcd_labels_test))\n",
    "#print(score_hh, score_qcd)\n",
    "\n",
    "#pred_hh = best_model.predict(np.array(hh_data_test))\n",
    "#pred_qcd = best_model.predict(np.array(qcd_data_test))\n",
    "\n",
    "pred_hh = model.predict(np.array(hh_data_test))\n",
    "pred_qcd = model.predict(np.array(qcd_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nBins = 40\n",
    "predictionResults = {'hh_pred':pred_hh[:,0], 'qcd_pred':pred_qcd[:,0]}\n",
    "compareManyHistograms( predictionResults, ['hh_pred', 'qcd_pred'], 2, 'Signal Prediction', 'LBN Signal Score', 0, 1, _nBins, _yMax = 5, _normed=True, _savePlot=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 4. Get best cut value for ff-NN assuming some minimal amount of signal\n",
    "returnBestCutValue('ff-NN', pred_hh[:,0].copy(), pred_qcd[:,0].copy(), _minBackground=200, _testingFraction=testingFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 5. Get signifiance for any user-specified NN score cut value\n",
    "lumiscale_hh  = getLumiScaleFactor(testingFraction, True)\n",
    "lumiscale_qcd = getLumiScaleFactor(testingFraction, False)\n",
    "cut = 0.81\n",
    "_nSignal = sum( value > cut for value in pred_hh)*lumiscale_hh\n",
    "_nBackground = sum( value > cut for value in pred_qcd)*lumiscale_qcd\n",
    "\n",
    "print('nSig = {0} , nBkg = {1} with significance = {2} for NN score > {3}'.format(_nSignal, _nBackground, _nSignal/np.sqrt(_nBackground), cut) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('models/allVars_100-50-50.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "#plt.plot(history.history['categorical_accuracy'])\n",
    "#plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('LBN Accuracy')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('LBN Model Loss')\n",
    "plt.ylabel('Loss [A.U.]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('LBN Model AUC')\n",
    "plt.ylabel('AUC [A.U.]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "testVectorsByEvent_ROC = testVectorsByEvent.copy()\n",
    "#top10_data_test_ROC = top10_data_test__norm.copy()\n",
    "#top10_data_test_ROC = top10_data_test_ROC.drop('isSignal', axis=1)\n",
    "\n",
    "y_pred = model.predict(testVectorsByEvent_ROC).ravel()\n",
    "falsePositiveRate, truePositiveRate, thresholds = roc_curve(testLabelsByEvent, y_pred)\n",
    "auc_keras = auc(falsePositiveRate, truePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(falsePositiveRate, truePositiveRate, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['jet{}_E', 'jet{}_px', 'jet{}_py', 'jet{}_pz', 'jet{}_m']\n",
    "for i in range(1,5):\n",
    "    varN = [x.format(i) for x in var]\n",
    "    print(varN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "je"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_model = createModelLBN('dummy.hdf5')\n",
    "dumb_model.layers[0] = False\n",
    "dumb_model.layers[1].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
