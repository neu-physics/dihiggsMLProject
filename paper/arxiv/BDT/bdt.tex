\label{sec:BDT}
Boosted Decision Trees (BDTs) have a long history in high energy physics from enabling the first observation of single top production at the Tevatron~\cite{Abazov_2009} to helping in the discovery of the Higgs boson at the LHC~\cite{Aad_2012, Chatrchyan_2012}. A decision tree functions by making a series of cuts (or decisions) that maximize the separation between signal and background events in a single dimension. Each cut produces a branch in the tree containing independent populations. The depth of the tree sets the number of decisions a tree will make, and a well-designed tree will have end-nodes that efficiently separate and properly identify the constituent classes. Any series of cuts for identifying events will inevitably misclassify some events, and there are many strategies for improving the results. A boosted decision tree attempts to improve the classification by creating a new set of data from the improperly classified events and training a new decision tree on these inputs. Each step of re-training with misclassified events is called a \textit{boost}, and the total prediction for an event is the weighted sum of predictions from the orignal tree and the boosted trees where each sequential boost recieves a smaller weight in the sum.

The BDT trained for dihiggs detection was built using the xgboost package~\cite{xgboost}. The top seventeen reconstructed and event-level variables ranked by KS separability (discussed in Section~\ref{label:physics}) were used in training. The hyperparameters describing the boosted decision tree were optimized for maximum $S/\sqrt{B}$. The optimal hyperparamters were found to be as follows: multiplicative boost factor of 0.1, maximum tree depth of 9, gamma (minimum loss reduction needed for further partition) of 1.1, and an L2 regularization term of 8.28.

\begin{figure}[!h]
\begin{center}
\includegraphics[width=3in]{BDT/bdt_pred}
\caption{Signal predictions of the trained BDT for signal and background samples independent from the training sets.}
\label{fig:bdt_pred}
\end{center}
\end{figure}

The predictions from the optimized BDT are shown in Figure~\ref{fig:bdt_pred}. A maximum significance of 1.84$\pm$0.09 was obtained, yielding 986 signal events and 2.8$\cdot 10^5$ background events. 

\subsubsection{PCA and Clustering Extensions}
Two additional transformations of the input variables were tested to try to improve the BDT performance. The first transformation was to pass the nominal kinematic inputs through a k-means clustering stage before training the BDT. K-means clustering is an unsupervised learning algorithm that finds unlabelled groupings in the phase-space defined by the input variables. The number of clusters to fit is a user-defined hyperparameter, and three different clusterings (15, 20, 40) were tested. The second transformation involved performing a principal component analysis (PCA) decomposition on the nominal kinematic inputs before passing through the clustering step and finally the BDT. PCA is a technique for finding an orthogonal basis of input data that minimizes the variance along each new axis. No transformation was found to improve the performance of the nominal configuration, and the results are shown in Table~\ref{tab:bdtPCACluster}.

\begin{table}[h!]
\label{tab:bdtPCACluster}
\begin{center}
  %\hskip-4.0cm
    \begin{tabular}{|l|c|c|c|} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \hline\hline
      \textbf{Method} & $S/\sqrt{B}$ & N$_{sig}$ & N$_{bkg}$ \\
      \hline
      Nominal BDT & 1.84 $\pm$ 0.09 & 986.3  & 2.9$\cdot 10^5$ \\
      15 Clusters & 1.29 $\pm$ 0.02 & 2100.2 & 2.7$\cdot 10^6$ \\
      15 Clusters + PCA & 1.25 $\pm$ 0.02 & 2189.5 & 3.1$\cdot 10^6$ \\         
      20 Clusters & 1.30 $\pm$ 0.02 & 2260.6 & 3.0$\cdot 10^6$ \\
      20 Clusters + PCA & 1.27 $\pm$ 0.03 & 21756.4 & 1.9$\cdot 10^6$ \\         
      40 Clusters & 1.44 $\pm$ 0.03 & 1704.6 & 1.4$\cdot 10^6$ \\
      40 Clusters + PCA & 1.34 $\pm$ 0.02 & 2144.5 & 2.0$\cdot 10^6$ \\         
      \hline\hline
    \end{tabular}
    \caption{Significance and yields showing BDT performance for the nominal kinematic inputs, clustered kinematic inputs, and clustered inputs from a PCA decomposition. All yields are normalized to full HL-LHC dataset of 3000 fb$^{-1}$.}
    \end{center}
\end{table}



