\section{Results}
\label{sec:results}

The methods covered in this paper are by no means exhaustive of the ML landscape available to high energy physics, but a wide range of techniques and philosophies are covered. A weak observed trend is that the more complex the inputs are allowed to remain, the more information sophisticated algorithms can wring out of the data. This is less of a hard rule and more of a loose heuristic. Table~\ref{tab:summary} provides a summary of the methods described in the previous sections. The results of a traditional 1-D sequential cut technique is shown for comparison though it has not been previously described. 

\begin{table}[h!]
\label{tab:summary}
  \begin{center}
  \begin{tabular}{|l|c|c|c|} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \hline\hline
      \multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{0PU} \\
      \cline{2-4}
      & Best $S/\sqrt{B}$ & \textbf{N$_{\mathrm{Signal}}$} & \textbf{N$_{\mathrm{Background}}$} \\
      \hline
      Autoencoder           & 0.67 $\pm$ 0.01 & 5849.4 & 7.7 $\cdot$ $10^7$ \\
      1D-Rectangular Cuts   & 0.82 $\pm$ 0.XX & 3621.0 & 1.97 $\cdot$ $10^7$ \\
      k-Means Clustering    & 1.44 $\pm$ 0.02 & 1703.6 & 1.4 $\cdot$ $10^6$ \\
      Particle Flow Network & 1.62 $\pm$ 0.01 & 1.8 $\cdot$ $10^4$ & 1.2 $\cdot$ $10^8$ \\
      Boosted Decision Tree & 1.84 $\pm$ 0.09 & 986.3  & 2.8 $\cdot$ $10^5$ \\
      Lorentz Boost Network & 1.87 $\pm$ 0.08 & 1123.3 & 3.6 $\cdot$ $10^5$ \\
      Random Forest         & 2.04 $\pm$ 0.07 & 1154.7 & 3.2 $\cdot$ $10^5$ \\
      Feed-Forward NN       & 2.20 $\pm$ 0.07 & 1520.1 & 4.8 $\cdot$ $10^5$ \\
      Convolutional NN      & 2.85 $\pm$ 0.02 & - & - \\
      \hline\hline
    \end{tabular}
    \caption{Comaprison of method significance and signal/background yields normalized to full HL-LHC dataset of 3000 fb$^{-1}$.}
  \end{center}
\end{table}

An important caveat to keep in mind is that all results discussed here were determined in conditions with zero pileup. In higher pileup environments like those expected at the HL-LHC, reconstruction algorithms see serious reductions in correct combinatoric matching. This effect will certainly degrade the expected performance of techniques that rely on explicit event reconstruction. Methods that do not rely on event reconstruction (CNN, PFN) might be more robust to these effects, and this should be studied in further work. The unsupervised AE technique performed the worst among all the methods tested, but this is likely a reflection of a mismatch between problem and proposed solution rather than a statement on the use of unsupervised techniques in general. 

