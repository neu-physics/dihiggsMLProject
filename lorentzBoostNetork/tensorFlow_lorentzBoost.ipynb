{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do\n",
    "# 1) plot some variables before and after normalization. how do they compare?\n",
    "# X) try batch normalization in the network? re-do step1 maybe?\n",
    "# 3) to_categorical for signal and background preds?\n",
    "# 4) grid optimization? --> dropout rate, layers, nodes, etc\n",
    "# X) k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.utils import normalize, to_categorical\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.models import load_model\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n",
    "from lbn import LBN, LBNLayer\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '/home/btannenw/Desktop/ML/dihiggsMLProject/')\n",
    "from utils.commonFunctions import *\n",
    "\n",
    "#model_dir = os.path.join(tut.data_dir, \"lbn\", \"models\", name)\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.makedirs(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dihiggs file:  /home/btannenw/Desktop/ML/dihiggsMLProject/data/pp2hh4b_500kEvents_0PU_v2-05__top4inPt-4tags-10jets_combined_csv.csv\n",
      "QCD file:  /home/btannenw/Desktop/ML/dihiggsMLProject/data/ppTo4b_2MEvents_0PU_v2-05__top4inPt-4tags-10jets_combined_csv.csv\n"
     ]
    }
   ],
   "source": [
    "#*** 1. Import data and check stuff\n",
    "testingFraction = 0.3\n",
    "\n",
    "# *** A. Import Dataset\n",
    "hh_raw, qcd_raw = importDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.3195e+04, 4.0870e+04, 2.5949e+04, 1.1225e+04, 3.8130e+03,\n",
       "        1.1030e+03, 2.6100e+02, 5.6000e+01, 5.0000e+00, 4.0000e+00]),\n",
       " array([ 4. ,  4.9,  5.8,  6.7,  7.6,  8.5,  9.4, 10.3, 11.2, 12.1, 13. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(qcd_raw.nJets, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_sig = 78876 , N_bkg = 116481\n",
      "195357 rows of total data with  195357 labels [Train+Test]\n",
      "136749 rows of training data with  136749 labels [Train]\n",
      "58608 rows of testing data with  58608 labels [Test]\n"
     ]
    }
   ],
   "source": [
    "# *** 2. Make mix of dihiggs and QCD for specified variables\n",
    "jetLabels = ['1','2','3','4','5','6','7','8']\n",
    "jetVariables = ['energy', 'px', 'py', 'pz']\n",
    "variables_jetVects = ['jet{0}_{1}'.format(iJetLabel, iJetVariable) for iJetLabel in jetLabels for iJetVariable in jetVariables]\n",
    "\n",
    "# *** 2. Split testing and training\n",
    "jetVects_data_train, jetVects_data_test, jetVects_labels_train, jetVects_labels_test = makeTestTrainSamplesWithUserVariables(hh_raw, qcd_raw, variables_jetVects, testingFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136749, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** 2. Create jet vector inputs\n",
    "def returnJetVectorInputsToLBN(_df, _jetType='jet', _nJets=4):\n",
    "    \n",
    "    #flattened\n",
    "    _allVectorsFlattened = None\n",
    "    _var = [_jetType+'{}_energy', _jetType+'{}_px', _jetType+'{}_py', _jetType+'{}_pz']\n",
    "    \n",
    "    for i in range(1, _nJets + 1):\n",
    "        _varN = [x.format(i) for x in _var]\n",
    "        _jetNData = _df[ _varN ].astype(np.float32)\n",
    "        _vectN = [list(x) for x in _jetNData.values]\n",
    "        \n",
    "        if _allVectorsFlattened == None:\n",
    "            _allVectorsFlattened = _vectN\n",
    "        else:\n",
    "            _allVectorsFlattened = [ x + y for x,y in zip(_allVectorsFlattened, _vectN) ]\n",
    "\n",
    "    return np.array(_allVectorsFlattened)\n",
    "    \n",
    "\n",
    "nJets = 8\n",
    "jetType = 'jet'\n",
    "trainVectorsByEvent = returnJetVectorInputsToLBN( jetVects_data_train, jetType, nJets)\n",
    "testVectorsByEvent  = returnJetVectorInputsToLBN( jetVects_data_test, jetType, nJets)\n",
    "\n",
    "trainLabelsByEvent = np.array([[0.,1.] if x ==0 else [1.,0.] for x in jetVects_labels_train.isSignal]).astype(np.float32)\n",
    "testLabelsByEvent  = np.array([[0.,1.] if x ==0 else [1.,0.] for x in jetVects_labels_test.isSignal]).astype(np.float32)\n",
    "\n",
    "#np.array(jetVects_labels_train)\n",
    "np.shape(trainVectorsByEvent)\n",
    "#np.array(trainLabelsByEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 3A. Define LBN model and train\n",
    "def createModelLBN(_nodesInFirstHiddenLayer=80, _nodesInSecondHiddenLayer=256, _hiddenActivation='relu', _outputActivation='sigmoid', _weightsFile=''):\n",
    "    \"\"\"make lbn model\"\"\"\n",
    "    #init = tf.keras.initializers.RandomNormal(mean=0., stddev=0.1, seed=123)\n",
    " \n",
    "    metrics = [\n",
    "        tf.keras.metrics.categorical_accuracy,\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    \n",
    "    #l2_reg = l2(1e-4)\n",
    "    \n",
    "    l2_reg = tf.keras.regularizers.l2(1e-4)\n",
    "    \n",
    "    dense_kwargs_IML = dict(\n",
    "        activation=\"selu\",\n",
    "        kernel_initializer=tf.keras.initializers.lecun_normal(),\n",
    "        kernel_regularizer=l2_reg,\n",
    "    )\n",
    "\n",
    "    dense_kwargs = dict(\n",
    "        activation=_hiddenActivation,\n",
    "        kernel_initializer=tf.keras.initializers.lecun_normal(),\n",
    "        kernel_regularizer=l2_reg,\n",
    "    )\n",
    "\n",
    "    _model = tf.keras.models.Sequential()\n",
    "\n",
    "    features = [\"E\", \"pt\", \"eta\", \"phi\", \"m\", \"pair_dr\"]\n",
    "    _model.add(LBNLayer(5, boost_mode=LBN.PAIRS, features=features))\n",
    "    _model.add(tf.keras.layers.BatchNormalization(axis=1))\n",
    "\n",
    "\n",
    "    _model.add(tf.keras.layers.Dense(80, **dense_kwargs))#, kernel_regularizer=l2_reg))\n",
    "    _model.add(tf.keras.layers.Dense(256, **dense_kwargs))#, kernel_regularizer=l2_reg))\n",
    "\n",
    "\n",
    "    #_model.add(tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=init))\n",
    "    #_model.add(tf.keras.layers.Dense(750, activation='relu'))#, kernel_regularizer=l2_reg))\n",
    "    #_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dropout(0.2))\n",
    "    #_model.add(BatchNormalization())\n",
    "\n",
    "    #_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    #_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    _model.add(tf.keras.layers.Dense(2, activation=_outputActivation, kernel_regularizer=l2_reg))\n",
    "        \n",
    "    _model.compile(loss='binary_crossentropy',\n",
    "                  #loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  #metrics=['accuracy']\n",
    "                  metrics = metrics\n",
    "                 )\n",
    "\n",
    "    if _weightsFile !='':\n",
    "        _model = _model.get_weights(_weightsFile)\n",
    "        for _layer in _model.layers:\n",
    "        #    _layer.trainable_ = False\n",
    "\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136749 samples, validate on 58608 samples\n",
      "Epoch 1/5\n",
      "136749/136749 [==============================] - 10s 75us/sample - loss: 0.5828 - categorical_accuracy: 0.6965 - auc: 0.7752 - val_loss: 0.5461 - val_categorical_accuracy: 0.7271 - val_auc: 0.8094\n",
      "Epoch 2/5\n",
      "136749/136749 [==============================] - 7s 48us/sample - loss: 0.5288 - categorical_accuracy: 0.7414 - auc: 0.8239 - val_loss: 0.5136 - val_categorical_accuracy: 0.7522 - val_auc: 0.8352\n",
      "Epoch 3/5\n",
      "136749/136749 [==============================] - 7s 52us/sample - loss: 0.5022 - categorical_accuracy: 0.7607 - auc: 0.8436 - val_loss: 0.4919 - val_categorical_accuracy: 0.7664 - val_auc: 0.8507\n",
      "Epoch 4/5\n",
      "136749/136749 [==============================] - 7s 50us/sample - loss: 0.4856 - categorical_accuracy: 0.7731 - auc: 0.8553 - val_loss: 0.4779 - val_categorical_accuracy: 0.7748 - val_auc: 0.8600\n",
      "Epoch 5/5\n",
      "136749/136749 [==============================] - 8s 58us/sample - loss: 0.4729 - categorical_accuracy: 0.7814 - auc: 0.8638 - val_loss: 0.4717 - val_categorical_accuracy: 0.7809 - val_auc: 0.8645\n",
      "24350\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=10)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=.001)\n",
    "\n",
    "#mc = ModelCheckpoint('best_model.hdf5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "mc = ModelCheckpoint('best_model.hdf5', #filepath=os.path.join(model_dir, name),\n",
    "                    monitor=\"val_loss\", mode='min', save_weights_only=True, save_best_only=True)\n",
    " \n",
    "\n",
    "#model = createModelLBN(_outputActivation='softmax') # 1.77+/0.04, 1.84 +/- 0.06\n",
    "model = createModelLBN(_outputActivation='sigmoid') # 1.81+/0.06\n",
    "\n",
    "history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=5, validation_data = (testVectorsByEvent, testLabelsByEvent), batch_size=400, callbacks=[es, mc])\n",
    "#history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=10, validation_data = (testVectorsByEvent, testLabelsByEvent))\n",
    "print(model.count_params())\n",
    "\n",
    "# load the saved model\n",
    "#model_best = model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f2e7c969a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# *** 3B. Define low-level NN using jet vectors for comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnInputNodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainVectorsByEvent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model.add(Dense(100, input_dim=nInputNodes, activation='relu'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# *** 3B. Define low-level NN using jet vectors for comparison\n",
    "model_nn = tf.keras.models.Sequential()\n",
    "nInputNodes = len(trainVectorsByEvent[0]) \n",
    "#model.add(Dense(100, input_dim=nInputNodes, activation='relu'))\n",
    "\n",
    "model_nn.add(tf.keras.layers.Dense(128, input_dim = nInputNodes, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model_nn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model_nn.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_nn.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_nn.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_nn = model_nn.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=50, validation_data = (testVectorsByEvent, testLabelsByEvent), batch_size=400)\n",
    "#history = model.fit( trainVectorsByEvent, trainLabelsByEvent, epochs=10, validation_data = (testVectorsByEvent, testLabelsByEvent))\n",
    "print(model_nn.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'> <class 'tensorflow.python.keras.engine.sequential.Sequential'> <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'> <class 'tensorflow.python.keras.engine.sequential.Sequential'> <class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
      "[<tf.Variable 'sequential_50/lbn_layer_50/particle_weights:0' shape=(8, 5) dtype=float32, numpy=\n",
      "array([[-0.01211984, -0.05901867,  0.0799114 ,  0.20018089, -0.08554918],\n",
      "       [-0.01984012,  0.24192734, -0.18966764, -0.01419622, -0.06165869],\n",
      "       [-0.15962172, -0.08340927, -0.2245349 , -0.21469025, -0.02605469],\n",
      "       [-0.11619164,  0.09109826,  0.15307516,  0.50382996, -0.00691813],\n",
      "       [-0.12506823, -0.00648024, -0.0081202 , -0.25645605,  0.07116049],\n",
      "       [-0.19403808,  0.004836  ,  0.24061215,  0.23136166, -0.40072986],\n",
      "       [-0.15869945,  0.00600046, -0.01939927, -0.14053008, -0.17276846],\n",
      "       [ 0.0450042 , -0.07937684,  0.0747517 ,  0.0882839 , -0.08336012]],\n",
      "      dtype=float32)>, <tf.Variable 'sequential_50/lbn_layer_50/restframe_weights:0' shape=(8, 5) dtype=float32, numpy=\n",
      "array([[ 0.13514008,  0.07464468,  0.13580616, -0.28035623,  0.13325423],\n",
      "       [ 0.15019143,  0.16661151, -0.13818632,  0.00130665, -0.15990947],\n",
      "       [-0.09780959,  0.02419901, -0.11369093, -0.40399504,  0.15724295],\n",
      "       [ 0.23615693, -0.17211822,  0.13797903, -0.04919645,  0.07922193],\n",
      "       [-0.1832207 ,  0.2178595 , -0.05077602, -0.22239836,  0.02383332],\n",
      "       [ 0.05841998, -0.18173043,  0.03867433, -0.08362173, -0.33179456],\n",
      "       [ 0.02597679,  0.36232233, -0.17621201,  0.00234131, -0.03752411],\n",
      "       [ 0.01169902,  0.25821382, -0.05223146,  0.04009561, -0.25342318]],\n",
      "      dtype=float32)>, <tf.Variable 'sequential_50/batch_normalization_50/gamma:0' shape=(35,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'sequential_50/batch_normalization_50/beta:0' shape=(35,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'sequential_50/batch_normalization_50/moving_mean:0' shape=(35,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'sequential_50/batch_normalization_50/moving_variance:0' shape=(35,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'sequential_50/dense_150/kernel:0' shape=(35, 80) dtype=float32, numpy=\n",
      "array([[-0.20170178,  0.14484791, -0.33426297, ..., -0.14705424,\n",
      "         0.07829461,  0.14822055],\n",
      "       [-0.07389101, -0.20364328, -0.03207173, ..., -0.11106997,\n",
      "        -0.04637271, -0.05679436],\n",
      "       [ 0.24007767, -0.04002495, -0.3363248 , ..., -0.3460026 ,\n",
      "        -0.09153874,  0.23326255],\n",
      "       ...,\n",
      "       [-0.20362179,  0.10444582, -0.08438513, ..., -0.22751574,\n",
      "         0.24267271,  0.1160427 ],\n",
      "       [ 0.01312958,  0.18367809,  0.08135139, ..., -0.06011335,\n",
      "        -0.17577943,  0.23836401],\n",
      "       [ 0.0631659 , -0.01388421,  0.13182525, ...,  0.23913774,\n",
      "         0.29288065,  0.15316387]], dtype=float32)>, <tf.Variable 'sequential_50/dense_150/bias:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'sequential_50/dense_151/kernel:0' shape=(80, 256) dtype=float32, numpy=\n",
      "array([[-0.00559832, -0.10134448,  0.11687046, ..., -0.02786374,\n",
      "        -0.18481876, -0.06518722],\n",
      "       [ 0.00792033,  0.19285047, -0.04418394, ...,  0.08998485,\n",
      "         0.00056055,  0.15552266],\n",
      "       [-0.03689235, -0.00758784,  0.06316566, ..., -0.01310993,\n",
      "         0.14285071,  0.0919444 ],\n",
      "       ...,\n",
      "       [-0.12411957,  0.06940464, -0.18447872, ..., -0.17429562,\n",
      "        -0.20687196,  0.1791423 ],\n",
      "       [ 0.13347842,  0.04426348, -0.11652118, ...,  0.09932066,\n",
      "        -0.00916955, -0.09115577],\n",
      "       [ 0.10335325, -0.23363487, -0.02018941, ...,  0.06646886,\n",
      "         0.0206376 ,  0.01260799]], dtype=float32)>, <tf.Variable 'sequential_50/dense_151/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'sequential_50/dense_152/kernel:0' shape=(256, 2) dtype=float32, numpy=\n",
      "array([[-0.10740957, -0.03063032],\n",
      "       [ 0.14493582, -0.01421672],\n",
      "       [-0.00804803, -0.08335505],\n",
      "       [-0.0551065 ,  0.02291174],\n",
      "       [ 0.01531146, -0.04147239],\n",
      "       [ 0.14773935,  0.07422805],\n",
      "       [ 0.12339637, -0.12887926],\n",
      "       [-0.07986554, -0.04312582],\n",
      "       [-0.06140731, -0.03281739],\n",
      "       [ 0.01036857, -0.056725  ],\n",
      "       [ 0.06302933,  0.07203534],\n",
      "       [-0.12582074, -0.02511357],\n",
      "       [ 0.04148456, -0.08420663],\n",
      "       [ 0.02985625,  0.03289327],\n",
      "       [-0.02524713, -0.09950083],\n",
      "       [-0.12729843, -0.01363833],\n",
      "       [-0.09968117, -0.05094188],\n",
      "       [-0.12468607,  0.10460132],\n",
      "       [ 0.12850472,  0.06246208],\n",
      "       [-0.02552187, -0.07112848],\n",
      "       [-0.05194538, -0.06387915],\n",
      "       [-0.01614423,  0.1106956 ],\n",
      "       [-0.14935015, -0.04341408],\n",
      "       [-0.06688414,  0.13395596],\n",
      "       [ 0.07964335, -0.00881261],\n",
      "       [ 0.12992933,  0.08125719],\n",
      "       [-0.08371536, -0.03415768],\n",
      "       [ 0.00256003,  0.11014009],\n",
      "       [-0.02313694, -0.13402046],\n",
      "       [-0.05140684, -0.05212608],\n",
      "       [ 0.10751146, -0.13942955],\n",
      "       [-0.13489386,  0.04296985],\n",
      "       [ 0.04959466,  0.0949333 ],\n",
      "       [ 0.08038856, -0.04638435],\n",
      "       [-0.12128662,  0.06412096],\n",
      "       [-0.05231151,  0.09826091],\n",
      "       [ 0.03038061, -0.07592751],\n",
      "       [ 0.02965158, -0.00287966],\n",
      "       [-0.01069568,  0.09854442],\n",
      "       [ 0.09556721, -0.12032647],\n",
      "       [ 0.08030213, -0.09400292],\n",
      "       [ 0.03260815, -0.12280194],\n",
      "       [ 0.04175948, -0.08042775],\n",
      "       [ 0.028762  , -0.0855583 ],\n",
      "       [-0.13893434, -0.1335202 ],\n",
      "       [-0.03625003, -0.13633388],\n",
      "       [-0.05152886, -0.10221572],\n",
      "       [-0.06580444, -0.01045237],\n",
      "       [ 0.06183885, -0.14349788],\n",
      "       [-0.15019687,  0.12932396],\n",
      "       [-0.06374706,  0.11793053],\n",
      "       [-0.09852308, -0.08428335],\n",
      "       [-0.014477  , -0.0531062 ],\n",
      "       [ 0.05567755, -0.14385739],\n",
      "       [-0.11983509, -0.03464691],\n",
      "       [ 0.0737066 , -0.12359902],\n",
      "       [-0.08146644,  0.05738428],\n",
      "       [-0.07230654,  0.09780991],\n",
      "       [ 0.11184201, -0.04055776],\n",
      "       [ 0.10380712, -0.01590277],\n",
      "       [-0.03521436,  0.14312008],\n",
      "       [ 0.07497273,  0.00166598],\n",
      "       [-0.09429564, -0.09151484],\n",
      "       [-0.13541248,  0.12783816],\n",
      "       [ 0.11648884, -0.07867146],\n",
      "       [ 0.06339569,  0.14565918],\n",
      "       [ 0.11424553,  0.1502026 ],\n",
      "       [-0.11991765, -0.05398764],\n",
      "       [ 0.1342439 , -0.05976354],\n",
      "       [-0.08377618, -0.01903488],\n",
      "       [ 0.15140426,  0.07649136],\n",
      "       [-0.11372231, -0.00040907],\n",
      "       [ 0.11697096, -0.08670159],\n",
      "       [ 0.12990472, -0.14810418],\n",
      "       [ 0.11425039,  0.03825848],\n",
      "       [ 0.11461145,  0.0799087 ],\n",
      "       [ 0.13307816,  0.01968725],\n",
      "       [ 0.00407787, -0.07735182],\n",
      "       [-0.0144769 ,  0.01770245],\n",
      "       [-0.08707481, -0.10966419],\n",
      "       [ 0.06553371, -0.13841885],\n",
      "       [ 0.01267315, -0.09526052],\n",
      "       [ 0.13963938,  0.09568889],\n",
      "       [ 0.05075948, -0.1152574 ],\n",
      "       [ 0.00586212,  0.00259978],\n",
      "       [-0.04168832, -0.08744643],\n",
      "       [ 0.08588894, -0.0605185 ],\n",
      "       [ 0.10131237,  0.14560989],\n",
      "       [-0.12161287,  0.10514376],\n",
      "       [ 0.02364233, -0.00302775],\n",
      "       [-0.07436901,  0.04950464],\n",
      "       [ 0.03065792, -0.06913291],\n",
      "       [-0.13656421,  0.10648224],\n",
      "       [-0.10584888,  0.13251013],\n",
      "       [ 0.03562674, -0.12843157],\n",
      "       [-0.15042196, -0.07324735],\n",
      "       [ 0.05982994,  0.03305016],\n",
      "       [-0.04631872, -0.11868852],\n",
      "       [-0.11596596,  0.0039186 ],\n",
      "       [-0.1358617 , -0.1507221 ],\n",
      "       [ 0.05362809,  0.14569616],\n",
      "       [ 0.01856974,  0.09457073],\n",
      "       [ 0.10135344,  0.13747945],\n",
      "       [-0.1278465 , -0.04651055],\n",
      "       [ 0.15201661,  0.03036119],\n",
      "       [ 0.08439712, -0.05878764],\n",
      "       [-0.13979658,  0.0040075 ],\n",
      "       [-0.0261075 , -0.0697273 ],\n",
      "       [-0.1278266 ,  0.00030498],\n",
      "       [-0.00381295,  0.01914732],\n",
      "       [-0.03269821, -0.09368195],\n",
      "       [ 0.0206798 ,  0.02842224],\n",
      "       [ 0.1105524 ,  0.10786757],\n",
      "       [-0.03023387,  0.12628135],\n",
      "       [-0.06837764,  0.14018992],\n",
      "       [ 0.07935114, -0.12357467],\n",
      "       [-0.04158826,  0.14203516],\n",
      "       [-0.00652958,  0.05129296],\n",
      "       [ 0.11979818,  0.13432696],\n",
      "       [-0.01113817, -0.10648745],\n",
      "       [ 0.00047117,  0.05195557],\n",
      "       [ 0.03865176,  0.11518776],\n",
      "       [ 0.14992267, -0.00610022],\n",
      "       [ 0.11670491,  0.03445785],\n",
      "       [-0.04782578, -0.13372555],\n",
      "       [ 0.03037308, -0.07054526],\n",
      "       [-0.01196329, -0.10912813],\n",
      "       [-0.08352807, -0.14417394],\n",
      "       [-0.10426831, -0.02424428],\n",
      "       [-0.0954653 ,  0.12396857],\n",
      "       [ 0.03218333,  0.13419157],\n",
      "       [ 0.05067091,  0.10257119],\n",
      "       [ 0.07284693, -0.02646607],\n",
      "       [ 0.04294059,  0.01505892],\n",
      "       [-0.0052731 , -0.0242999 ],\n",
      "       [-0.09258367, -0.01035236],\n",
      "       [-0.06563123,  0.01821499],\n",
      "       [-0.10195608,  0.07920639],\n",
      "       [-0.01874767,  0.11285606],\n",
      "       [-0.1288951 ,  0.04851994],\n",
      "       [ 0.09494267,  0.13380465],\n",
      "       [-0.14592405, -0.01839648],\n",
      "       [-0.05000471,  0.1042867 ],\n",
      "       [ 0.01079985,  0.09471336],\n",
      "       [-0.06995196,  0.11703891],\n",
      "       [-0.08469646, -0.03431126],\n",
      "       [ 0.12281957, -0.10310138],\n",
      "       [-0.14505814,  0.0032739 ],\n",
      "       [ 0.05034527, -0.13247907],\n",
      "       [ 0.06087524, -0.0238775 ],\n",
      "       [ 0.07760753,  0.02866448],\n",
      "       [-0.13247934, -0.08458836],\n",
      "       [ 0.00543763,  0.05163746],\n",
      "       [ 0.10909617, -0.07901217],\n",
      "       [ 0.03541   , -0.0686356 ],\n",
      "       [ 0.0026329 , -0.13707206],\n",
      "       [-0.001443  ,  0.10344765],\n",
      "       [-0.06953005,  0.04064298],\n",
      "       [-0.14012243, -0.11628406],\n",
      "       [ 0.07134107, -0.04093672],\n",
      "       [-0.14592008, -0.0584025 ],\n",
      "       [ 0.11407307, -0.05061662],\n",
      "       [ 0.0083386 , -0.10754435],\n",
      "       [ 0.06749339,  0.12630224],\n",
      "       [ 0.04349516, -0.06098112],\n",
      "       [-0.06347655,  0.13258281],\n",
      "       [ 0.12250483, -0.14189786],\n",
      "       [ 0.100218  ,  0.05354729],\n",
      "       [ 0.13154835, -0.039715  ],\n",
      "       [-0.00072274,  0.08753777],\n",
      "       [-0.07521933, -0.12207651],\n",
      "       [ 0.05285124, -0.0440902 ],\n",
      "       [ 0.13043791, -0.13725938],\n",
      "       [ 0.10963461, -0.0219986 ],\n",
      "       [ 0.05202788,  0.09302236],\n",
      "       [ 0.11122018, -0.10727574],\n",
      "       [ 0.1277349 ,  0.06720628],\n",
      "       [-0.01113188,  0.13982347],\n",
      "       [ 0.04524033,  0.07945661],\n",
      "       [-0.13641325,  0.04930863],\n",
      "       [-0.10812278,  0.05106725],\n",
      "       [ 0.10915259,  0.0244737 ],\n",
      "       [ 0.10471389,  0.00222205],\n",
      "       [ 0.05666515, -0.0142858 ],\n",
      "       [-0.12260451,  0.11606863],\n",
      "       [-0.03750953, -0.05874285],\n",
      "       [-0.06917985,  0.10883522],\n",
      "       [ 0.11146182, -0.14271902],\n",
      "       [ 0.11631984,  0.05621092],\n",
      "       [-0.1250853 , -0.09503376],\n",
      "       [ 0.01953033,  0.00990608],\n",
      "       [ 0.1256671 ,  0.08933739],\n",
      "       [-0.03177365,  0.06752412],\n",
      "       [-0.08021287,  0.12511307],\n",
      "       [-0.13643466,  0.0179147 ],\n",
      "       [-0.05593758, -0.09891669],\n",
      "       [-0.00518119,  0.07379843],\n",
      "       [ 0.09695593, -0.14051165],\n",
      "       [ 0.05562158, -0.06764167],\n",
      "       [ 0.08516014, -0.03482104],\n",
      "       [ 0.06719773,  0.04154637],\n",
      "       [ 0.07235061,  0.01530012],\n",
      "       [ 0.00919415,  0.03445207],\n",
      "       [-0.07380309, -0.01728   ],\n",
      "       [-0.04910945,  0.03034349],\n",
      "       [-0.08157144, -0.03946725],\n",
      "       [ 0.07812622, -0.01883177],\n",
      "       [ 0.00834759,  0.02530089],\n",
      "       [ 0.12947473,  0.05284238],\n",
      "       [-0.01956153, -0.00626843],\n",
      "       [-0.0172648 , -0.06367289],\n",
      "       [ 0.13530624,  0.00953946],\n",
      "       [ 0.04023987,  0.02766834],\n",
      "       [ 0.01226765, -0.11899349],\n",
      "       [-0.12926942, -0.08312348],\n",
      "       [-0.03142617,  0.0720365 ],\n",
      "       [-0.07198291, -0.03034658],\n",
      "       [-0.01701778, -0.01733096],\n",
      "       [-0.03616852, -0.0223031 ],\n",
      "       [-0.03029121,  0.13231164],\n",
      "       [ 0.08437163,  0.01514688],\n",
      "       [-0.07202301, -0.06637581],\n",
      "       [ 0.10781863, -0.08341096],\n",
      "       [ 0.10295644, -0.09740644],\n",
      "       [ 0.09936032, -0.06819381],\n",
      "       [ 0.09132378,  0.02156578],\n",
      "       [-0.06874646, -0.07153079],\n",
      "       [-0.11716317,  0.00404434],\n",
      "       [ 0.00223209, -0.14753574],\n",
      "       [ 0.09069408,  0.08738746],\n",
      "       [ 0.08629823,  0.05507149],\n",
      "       [-0.1210271 , -0.06625986],\n",
      "       [-0.09724998, -0.09987126],\n",
      "       [-0.03194068,  0.14199954],\n",
      "       [-0.01742102, -0.02215315],\n",
      "       [ 0.00217366, -0.06517704],\n",
      "       [-0.02320632,  0.12911543],\n",
      "       [ 0.04531562,  0.06491031],\n",
      "       [ 0.05028936, -0.04895115],\n",
      "       [ 0.0785158 ,  0.01203907],\n",
      "       [ 0.03160062,  0.00215478],\n",
      "       [-0.01359902, -0.09576427],\n",
      "       [-0.00525732,  0.14819726],\n",
      "       [ 0.00587295, -0.02399904],\n",
      "       [-0.03998889,  0.13495141],\n",
      "       [-0.11985461,  0.0137374 ],\n",
      "       [ 0.00964755,  0.04677945],\n",
      "       [-0.05196989,  0.1432631 ],\n",
      "       [ 0.11063665, -0.01673876],\n",
      "       [ 0.07085252, -0.10880338],\n",
      "       [ 0.10142741, -0.12085886],\n",
      "       [-0.03683999,  0.04288585],\n",
      "       [ 0.02868514,  0.10176557],\n",
      "       [ 0.06949635, -0.04043403],\n",
      "       [ 0.05236751, -0.09079748],\n",
      "       [-0.03737864,  0.02899383]], dtype=float32)>, <tf.Variable 'sequential_50/dense_152/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5754ac468bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#dumb_model.save_weights('dummy2.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#print(np.shape(trainVectorsByEvent), np.shape(testVectorsByEvent))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36minput_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1594\u001b[0m     \"\"\"\n\u001b[1;32m   1595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m       raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[1;32m   1597\u001b[0m                            'and thus has no defined input shape.')\n\u001b[1;32m   1598\u001b[0m     all_input_shapes = set(\n",
      "\u001b[0;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "#model = model_best\n",
    "blank_model = createModelLBN()\n",
    "best_model = createModelLBN('best_model.hdf5')\n",
    "\n",
    "model.save_weights('dummy.hdf5', overwrite=True)\n",
    "dumb_model = createModelLBN('dummy.hdf5')\n",
    "\n",
    "#model_best = load_weights('/home/btannenw/Desktop/ML/dihiggsMLProject/lorentzBoostNetork/best_model.h5')\n",
    "print(type(model), type(best_model), type(blank_model))\n",
    "#best_model = model.load_weights('best_model.hdf5')\n",
    "#best_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(type(model), type(best_model), type(dumb_model))\n",
    "\n",
    "\n",
    "\n",
    "dumb_model.predict(testVectorsByEvent[0:10])\n",
    "print(dumb_model.weights)\n",
    "\n",
    "#dumb_model.predict(testVectorsByEvent[5:10])\n",
    "#print(dumb_model.weights)\n",
    "\n",
    "#dumb_model.save_weights('dummy2.hdf5')\n",
    "#print(np.shape(trainVectorsByEvent), np.shape(testVectorsByEvent))\n",
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58608, 2)\n"
     ]
    }
   ],
   "source": [
    "# *** 4. Do some very specific evaluation based on pure samples\n",
    "hh_data_test, hh_labels_test, qcd_data_test, qcd_labels_test = returnTestSamplesSplitIntoSignalAndBackground(testVectorsByEvent, testLabelsByEvent)\n",
    "\n",
    "#score_hh = model.evaluate(np.array(hh_data_test), np.array(hh_labels_test))\n",
    "#score_qcd = model.evaluate(np.array(qcd_data_test), np.array(qcd_labels_test))\n",
    "#print(score_hh, score_qcd)\n",
    "\n",
    "#pred_hh = best_model.predict(np.array(hh_data_test))\n",
    "#pred_qcd = best_model.predict(np.array(qcd_data_test))\n",
    "\n",
    "pred_hh = model.predict(np.array(hh_data_test))\n",
    "pred_qcd = model.predict(np.array(qcd_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nBins = 40\n",
    "predictionResults = {'hh_pred':pred_hh[:,0], 'qcd_pred':pred_qcd[:,0]}\n",
    "compareManyHistograms( predictionResults, ['hh_pred', 'qcd_pred'], 2, 'Signal Prediction', 'LBN Signal Score', 0, 1, _nBins, _yMax = 5, _normed=True, _savePlot=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 4. Get best cut value for ff-NN assuming some minimal amount of signal\n",
    "returnBestCutValue('ff-NN', pred_hh[:,0].copy(), pred_qcd[:,0].copy(), _minBackground=200, _testingFraction=testingFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** 5. Get signifiance for any user-specified NN score cut value\n",
    "lumiscale_hh  = getLumiScaleFactor(testingFraction, True)\n",
    "lumiscale_qcd = getLumiScaleFactor(testingFraction, False)\n",
    "cut = 0.81\n",
    "_nSignal = sum( value > cut for value in pred_hh)*lumiscale_hh\n",
    "_nBackground = sum( value > cut for value in pred_qcd)*lumiscale_qcd\n",
    "\n",
    "print('nSig = {0} , nBkg = {1} with significance = {2} for NN score > {3}'.format(_nSignal, _nBackground, _nSignal/np.sqrt(_nBackground), cut) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('models/allVars_100-50-50.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "#plt.plot(history.history['categorical_accuracy'])\n",
    "#plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('LBN Accuracy')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('LBN Model Loss')\n",
    "plt.ylabel('Loss [A.U.]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('LBN Model AUC')\n",
    "plt.ylabel('AUC [A.U.]')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "testVectorsByEvent_ROC = testVectorsByEvent.copy()\n",
    "#top10_data_test_ROC = top10_data_test__norm.copy()\n",
    "#top10_data_test_ROC = top10_data_test_ROC.drop('isSignal', axis=1)\n",
    "\n",
    "y_pred = model.predict(testVectorsByEvent_ROC).ravel()\n",
    "falsePositiveRate, truePositiveRate, thresholds = roc_curve(testLabelsByEvent, y_pred)\n",
    "auc_keras = auc(falsePositiveRate, truePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(falsePositiveRate, truePositiveRate, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['jet{}_E', 'jet{}_px', 'jet{}_py', 'jet{}_pz', 'jet{}_m']\n",
    "for i in range(1,5):\n",
    "    varN = [x.format(i) for x in var]\n",
    "    print(varN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "je"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_model = createModelLBN('dummy.hdf5')\n",
    "dumb_model.layers[0] = False\n",
    "dumb_model.layers[1].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
