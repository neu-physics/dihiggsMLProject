{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as utils\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703 rows of qcd data\n",
      "4605 rows of dihiggs data\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "qcd_raw = pd.read_csv('../HiggsReconstruction/EventPlotting/qcd_outputDataForLearning.csv')\n",
    "hh_raw = pd.read_csv('../HiggsReconstruction/EventPlotting/dihiggs_outputDataForLearning.csv')\n",
    "\n",
    "print(len(qcd_raw), \"rows of qcd data\")\n",
    "print(len(hh_raw), \"rows of dihiggs data\")\n",
    "# qcd_raw.head()\n",
    "\n",
    "# hh_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [hh_mass, h1_mass, h2_mass, hh_pt, h1_pt, h2_pt, deltaR(h1, h2), deltaR(h1 jets), deltaR(h2 jets), deltaPhi(h1, h2), deltaPhi(h1 jets), deltaPhi(h2 jets), met, met_phi, scalarHT, nJets, nBTags, isMatchable, jet1_pt, jet2_pt, jet3_pt, jet4_pt, jet1_eta, jet2_eta, jet3_eta, jet4_eta, jet1_phi, jet2_phi, jet3_phi, jet4_phi, jet1_mass, jet2_mass, jet3_mass, jet4_mass, jet1_px, jet2_px, jet3_px, jet4_px, jet1_py, jet2_py, jet3_py, jet4_py, jet1_pz, jet2_pz, jet3_pz, jet4_pz, jet1_energy, jet2_energy, jet3_energy, jet4_energy, jet1_btag, jet2_btag, jet3_btag, jet4_btag]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hh_raw[0:0]) # get names of all the data\n",
    "# exclude isMatchable, met, met_phi, scalarHT, nBTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted rows from dataframe\n",
    "hh_raw = hh_raw.drop(columns=['isMatchable', \n",
    "                              'met', 'met_phi', \n",
    "                              'nJets', \n",
    "                              'nBTags']);\n",
    "qcd_raw = qcd_raw.drop(columns=['isMatchable', \n",
    "                                'met', 'met_phi', \n",
    "                                'nJets', \n",
    "                                'nBTags']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "hh_all = np.array(hh_raw); qcd = np.array(qcd_raw); n_factors = np.shape(hh_all)[1]; print(n_factors)\n",
    "image_dim = (7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels to di-higgs\n",
    "hh_all=hh_all[:,:n_factors]\n",
    "hh_labels= np.zeros((len(hh_all),1))\n",
    "hh_labels = hh_labels+1\n",
    "hh_all = np.append(hh_all, hh_labels, axis=1)\n",
    "# hh_all = np.append(hh_all, 1-hh_labels, axis=1)## hh qcd labels \n",
    "\n",
    "qcd=qcd[:,:n_factors]\n",
    "qcd_labels= np.zeros((len(qcd),1))\n",
    "qcd = np.append(qcd, qcd_labels, axis=1) \n",
    "# qcd = np.append(qcd, 1-qcd_labels, axis=1)# qcd qcd labels\n",
    "\n",
    "hh = hh_all[0:len(qcd)]\n",
    "\n",
    "all_data = np.append(hh,qcd, axis=0) \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "all_labels = all_data[:,n_factors:]\n",
    "\n",
    "all_data = all_data[:,:n_factors]\n",
    "\n",
    "# scale the data by dividing it by the max value of each\n",
    "for i in range(np.shape(all_data)[1]):\n",
    "    all_data[:,i] = np.true_divide(all_data[:,i], np.max(all_data[:,i]))\n",
    "# print(all_data[:4])\n",
    "\n",
    "# at this point, there is a dataset with 49 columns of data and 2 columns of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 49)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.shape\n",
    "# all_data_as_pixels = np.ndarray(all_data.shape[0], all_data.shape[1], 3)\n",
    "value = np.empty((), dtype=object)\n",
    "value[()] = (0, 0, 0)\n",
    "all_data_as_pixels = np.zeros((all_data.shape[0], all_data.shape[1], 1), dtype=np.uint8)\n",
    "for i in range(np.shape(all_data)[1]): \n",
    "    for j in range(len(all_data[i])):\n",
    "#         print(all_data_as_pixels[i][j].shape)\n",
    "        feature = all_data[i][j]\n",
    "        all_data_as_pixels[i][j][0] = 255*feature\n",
    "#         all_data_as_pixels[i][j][1] = 255*feature\n",
    "#         all_data_as_pixels[i][j][2] = 255*feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_data_as_pixels[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 1)\n",
      "(3406, 49, 1)\n"
     ]
    }
   ],
   "source": [
    "# first_img_pixels = all_data_as_pixels[0]\n",
    "print(all_data_as_pixels[0].shape)\n",
    "print(all_data_as_pixels.shape)\n",
    "# first_img_pixels = first_img_pixels.reshape(image_dim[0],image_dim[1],3)\n",
    "# print(first_img_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2648\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typestr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2649\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 1), '|u1')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-76404c2fd09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# img_0 = Image.fromarray(images[0], 'RGB')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# img_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mimg_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mimg_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-76404c2fd09e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# img_0 = Image.fromarray(images[0], 'RGB')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# img_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mimg_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mimg_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LHCResearch/venv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2649\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "images_and_labels = []\n",
    "\n",
    "# images = np.reshape(all_data_as_pixels.shape[0], (image_dim[0],image_dim[1],3))\n",
    "\n",
    "\n",
    "for pixels, labels in zip(all_data_as_pixels, all_labels):\n",
    "    ''' zipping ensures that images array and labels array are the same length '''\n",
    "#     print(pixels.shape)\n",
    "    img = pixels.reshape(image_dim[0],image_dim[1],1)\n",
    "#     print(img.shape)\n",
    "    images.append(img)\n",
    "# #   images_and_labels.append(np.concatenate((img, labels), axis=1))\n",
    "print(images[0].shape)\n",
    "# w, h = 512, 512\n",
    "# data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "# data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
    "# for i in all_data_as_pixels:\n",
    "#     print(all_data_as_pixels[i].shape)\n",
    "#     img_pixels = all_data_as_pixels[i]\n",
    "#     img_pixels = img_pixels.reshape(image_dim[0],image_dim[1],3)\n",
    "#     img = Image.fromarray(img_pixels, 'RGB')\n",
    "#     images[i] = img\n",
    "\n",
    "# img = Image.fromarray(first_img_pixels, 'RGB')\n",
    "# img.save('my.png')\n",
    "# img.show()\n",
    "# img_0 = Image.fromarray(images[0], 'RGB')\n",
    "# img_0\n",
    "img_dataset = [Image.fromarray(img) for img in images]\n",
    "img_dataset[0]\n",
    "len(img_dataset)\n",
    "# images.shape\n",
    "print(len(img_dataset))\n",
    "# img_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# plt.imshow(all_data_as_pixels[0].reshape(image_dim[0],image_dim[1],3), cmap='Greys')\n",
    "# plt.imshow(images[0], cmap='Greys')\n",
    "import cv2\n",
    "print(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b49a80407c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_dataset = tf.data.D÷ataset.from_tensor_slices((np.array(images), all_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, all_labels, train_size=0.7, test_size=0.3, random_state=42)\n",
    "# train_dataset = tf.data.D÷ataset.from_tensor_slices((np.array(images), all_labels))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3406, 7, 7, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(train_data))\n",
    "# train_data[0]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2384, 7, 7, 1)\n",
      "x_train shape: (2384, 7, 7, 1)\n",
      "Number of images in x_train 2384\n",
      "Number of images in x_test 1022\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "img_rows = 7\n",
    "img_cols = 7\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0622 19:59:02.514168 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0622 19:59:02.530984 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0622 19:59:02.534003 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0622 19:59:02.550528 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0622 19:59:02.578229 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0622 19:59:02.595512 4548347328 deprecation.py:506] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0622 19:59:02.645282 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0622 19:59:02.670290 4548347328 deprecation_wrapper.py:119] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0622 19:59:02.828629 4548347328 deprecation.py:323] From /Users/annacuddeback/LHCResearch/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2384, 7, 7, 1)\n",
      "Epoch 1/10\n",
      "2384/2384 [==============================] - 0s 188us/step - loss: 1.8212 - acc: 0.5076\n",
      "Epoch 2/10\n",
      "2384/2384 [==============================] - 0s 71us/step - loss: 0.7672 - acc: 0.5055\n",
      "Epoch 3/10\n",
      "2384/2384 [==============================] - 0s 74us/step - loss: 0.7246 - acc: 0.4870\n",
      "Epoch 4/10\n",
      "2384/2384 [==============================] - 0s 57us/step - loss: 0.7018 - acc: 0.5214\n",
      "Epoch 5/10\n",
      "2384/2384 [==============================] - 0s 53us/step - loss: 0.6973 - acc: 0.5227\n",
      "Epoch 6/10\n",
      "2384/2384 [==============================] - 0s 52us/step - loss: 0.7025 - acc: 0.5034\n",
      "Epoch 7/10\n",
      "2384/2384 [==============================] - 0s 50us/step - loss: 0.6977 - acc: 0.5076\n",
      "Epoch 8/10\n",
      "2384/2384 [==============================] - 0s 50us/step - loss: 0.6994 - acc: 0.4929\n",
      "Epoch 9/10\n",
      "2384/2384 [==============================] - 0s 55us/step - loss: 0.6972 - acc: 0.4904\n",
      "Epoch 10/10\n",
      "2384/2384 [==============================] - 0s 66us/step - loss: 0.6896 - acc: 0.5046\n",
      "1022/1022 [==============================] - 0s 81us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6832342839520972, 0.495107631744004]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(7, kernel_size=(2,2), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(50, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "print(x_train.shape)\n",
    "model.fit(x=x_train,y=y_train, epochs=10)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_images(img_array, labels):\n",
    "    width, height, n_channels = img_array[0].shape\n",
    "    print(width, height, n_channels)\n",
    "    num_images = len(img_array)\n",
    "    print(num_images)\n",
    "    avg_hh_image = np.zeros((width, height, n_channels), np.float)\n",
    "    avg_qcd_image = np.zeros((width, height, n_channels), np.float)\n",
    "    n_hh = 0\n",
    "    n_qcd = 0\n",
    "    for img, label in zip(img_array, labels): \n",
    "        if(label[0]==1):\n",
    "#             print(\"HH\")\n",
    "            avg_hh_image = avg_hh_image + img\n",
    "            n_hh = n_hh +1\n",
    "        if(label[0]==0):\n",
    "            avg_qcd_image = avg_qcd_image + img\n",
    "            n_qcd = n_qcd+1\n",
    "    avg_hh_image = avg_hh_image/n_hh\n",
    "    avg_qcd_image = avg_qcd_image/n_qcd\n",
    "#     print(avg_image)\n",
    "    avg_hh_image = np.array(np.round(avg_hh_image), dtype=np.uint8)\n",
    "    avg_qcd_image = np.array(np.round(avg_qcd_image), dtype=np.uint8)\n",
    "#     print(avg_image)\n",
    "#     plt.imshow(avg_hh_image, cmap='Greys');\n",
    "#     plt.imshow(avg_qcd_image, cmap='Greys');\n",
    "#     print(avg_hh_image)\n",
    "#     print(\"____\")\n",
    "#     print(avg_qcd_image)\n",
    "    return avg_hh_image, avg_qcd_image\n",
    "hh_avg_img, qcd_avg_img = get_average_images(images, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hh_avg_img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(qcd_avg_img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
