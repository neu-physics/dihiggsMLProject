{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adapted from \n",
    "## https://github.com/yhuag/neural-network-lab/blob/master/Feedforward%20Neural%20Network.ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as utils\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 12        # The image size = 28 x 28 = 784\n",
    "# hidden_size = 500      # The number of nodes at the hidden layer\n",
    "# num_classes = 2        # The number of output classes. In this case, from 0 to 9\n",
    "# num_epochs = 5         # The number of times entire dataset is trained\n",
    "# batch_size = 100       # The size of input data took for one iteration\n",
    "# learning_rate = 0.001  # The speed of convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703 rows of qcd data\n",
      "4605 rows of dihiggs data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hh_mass</th>\n",
       "      <th>h1_mass</th>\n",
       "      <th>h2_mass</th>\n",
       "      <th>hh_pt</th>\n",
       "      <th>h1_pt</th>\n",
       "      <th>h2_pt</th>\n",
       "      <th>deltaR(h1, h2)</th>\n",
       "      <th>deltaR(h1 jets)</th>\n",
       "      <th>deltaR(h2 jets)</th>\n",
       "      <th>deltaPhi(h1, h2)</th>\n",
       "      <th>...</th>\n",
       "      <th>jet3_pz</th>\n",
       "      <th>jet4_pz</th>\n",
       "      <th>jet1_energy</th>\n",
       "      <th>jet2_energy</th>\n",
       "      <th>jet3_energy</th>\n",
       "      <th>jet4_energy</th>\n",
       "      <th>jet1_btag</th>\n",
       "      <th>jet2_btag</th>\n",
       "      <th>jet3_btag</th>\n",
       "      <th>jet4_btag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>357.863363</td>\n",
       "      <td>148.291836</td>\n",
       "      <td>158.296646</td>\n",
       "      <td>159.989384</td>\n",
       "      <td>146.375635</td>\n",
       "      <td>44.305395</td>\n",
       "      <td>2.173180</td>\n",
       "      <td>2.399412</td>\n",
       "      <td>3.045172</td>\n",
       "      <td>-1.399745</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.743157</td>\n",
       "      <td>-193.100557</td>\n",
       "      <td>213.758220</td>\n",
       "      <td>33.357314</td>\n",
       "      <td>109.728774</td>\n",
       "      <td>199.436112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>398.807335</td>\n",
       "      <td>96.553640</td>\n",
       "      <td>58.554601</td>\n",
       "      <td>79.057467</td>\n",
       "      <td>159.554932</td>\n",
       "      <td>127.973055</td>\n",
       "      <td>3.027527</td>\n",
       "      <td>1.343736</td>\n",
       "      <td>1.118390</td>\n",
       "      <td>-2.628797</td>\n",
       "      <td>...</td>\n",
       "      <td>159.218959</td>\n",
       "      <td>26.364061</td>\n",
       "      <td>145.013069</td>\n",
       "      <td>49.268918</td>\n",
       "      <td>196.843044</td>\n",
       "      <td>36.066384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>517.175766</td>\n",
       "      <td>110.271880</td>\n",
       "      <td>130.164227</td>\n",
       "      <td>345.167743</td>\n",
       "      <td>311.858661</td>\n",
       "      <td>195.516589</td>\n",
       "      <td>1.993485</td>\n",
       "      <td>0.697377</td>\n",
       "      <td>1.152385</td>\n",
       "      <td>-1.705208</td>\n",
       "      <td>...</td>\n",
       "      <td>119.529521</td>\n",
       "      <td>120.680121</td>\n",
       "      <td>236.958103</td>\n",
       "      <td>93.822710</td>\n",
       "      <td>169.676742</td>\n",
       "      <td>166.284766</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703.807212</td>\n",
       "      <td>179.640526</td>\n",
       "      <td>166.136193</td>\n",
       "      <td>218.966737</td>\n",
       "      <td>339.262375</td>\n",
       "      <td>272.492484</td>\n",
       "      <td>2.518050</td>\n",
       "      <td>2.053376</td>\n",
       "      <td>2.090557</td>\n",
       "      <td>-2.441515</td>\n",
       "      <td>...</td>\n",
       "      <td>-240.496539</td>\n",
       "      <td>-109.657444</td>\n",
       "      <td>927.030920</td>\n",
       "      <td>36.379140</td>\n",
       "      <td>362.014352</td>\n",
       "      <td>111.759012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258.159408</td>\n",
       "      <td>36.588619</td>\n",
       "      <td>25.013392</td>\n",
       "      <td>95.051098</td>\n",
       "      <td>138.921709</td>\n",
       "      <td>46.393858</td>\n",
       "      <td>3.514808</td>\n",
       "      <td>0.549648</td>\n",
       "      <td>0.997364</td>\n",
       "      <td>-2.869764</td>\n",
       "      <td>...</td>\n",
       "      <td>-129.592083</td>\n",
       "      <td>-71.691360</td>\n",
       "      <td>109.019537</td>\n",
       "      <td>36.042242</td>\n",
       "      <td>133.506407</td>\n",
       "      <td>74.563495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hh_mass     h1_mass     h2_mass       hh_pt       h1_pt       h2_pt  \\\n",
       "0  357.863363  148.291836  158.296646  159.989384  146.375635   44.305395   \n",
       "1  398.807335   96.553640   58.554601   79.057467  159.554932  127.973055   \n",
       "2  517.175766  110.271880  130.164227  345.167743  311.858661  195.516589   \n",
       "3  703.807212  179.640526  166.136193  218.966737  339.262375  272.492484   \n",
       "4  258.159408   36.588619   25.013392   95.051098  138.921709   46.393858   \n",
       "\n",
       "   deltaR(h1, h2)  deltaR(h1 jets)  deltaR(h2 jets)  deltaPhi(h1, h2)  \\\n",
       "0        2.173180         2.399412         3.045172         -1.399745   \n",
       "1        3.027527         1.343736         1.118390         -2.628797   \n",
       "2        1.993485         0.697377         1.152385         -1.705208   \n",
       "3        2.518050         2.053376         2.090557         -2.441515   \n",
       "4        3.514808         0.549648         0.997364         -2.869764   \n",
       "\n",
       "     ...         jet3_pz     jet4_pz  jet1_energy  jet2_energy  jet3_energy  \\\n",
       "0    ...      -68.743157 -193.100557   213.758220    33.357314   109.728774   \n",
       "1    ...      159.218959   26.364061   145.013069    49.268918   196.843044   \n",
       "2    ...      119.529521  120.680121   236.958103    93.822710   169.676742   \n",
       "3    ...     -240.496539 -109.657444   927.030920    36.379140   362.014352   \n",
       "4    ...     -129.592083  -71.691360   109.019537    36.042242   133.506407   \n",
       "\n",
       "   jet4_energy  jet1_btag  jet2_btag  jet3_btag  jet4_btag  \n",
       "0   199.436112          1          1          1          1  \n",
       "1    36.066384          1          1          1          1  \n",
       "2   166.284766          1          1          1          1  \n",
       "3   111.759012          1          1          1          1  \n",
       "4    74.563495          1          1          1          1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "qcd_raw = pd.read_csv('../HiggsReconstruction/EventPlotting/qcd_outputDataForLearning.csv')\n",
    "hh_raw = pd.read_csv('../HiggsReconstruction/EventPlotting/dihiggs_outputDataForLearning.csv')\n",
    "\n",
    "print(len(qcd_raw), \"rows of qcd data\")\n",
    "print(len(hh_raw), \"rows of dihiggs data\")\n",
    "qcd_raw.head()\n",
    "\n",
    "hh_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make higgs and qcd sets from raw data\n",
    "# hh_all = hh_raw[['h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'jet1_pz', 'jet2_pz', 'jet3_pz', 'jet4_pz', 'jet1_energy', 'jet2_energy', 'jet3_energy', 'jet4_energy']]\n",
    "# qcd = qcd_raw[['h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'jet1_pz', 'jet2_pz', 'jet3_pz', 'jet4_pz', 'jet1_energy', 'jet2_energy', 'jet3_energy', 'jet4_energy']]\n",
    "\n",
    "# hh_all = hh_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)']]\n",
    "# qcd = qcd_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)']]\n",
    "\n",
    "#same as ruhi\n",
    "# hh_all = hh_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'deltaPhi(h1, h2)', 'deltaPhi(h1 jets)', 'deltaPhi(h2 jets)']]\n",
    "# qcd = qcd_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'deltaPhi(h1, h2)', 'deltaPhi(h1 jets)', 'deltaPhi(h2 jets)']]\n",
    "\n",
    "hh_all = hh_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1, h2)', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'deltaPhi(h1, h2)', 'deltaPhi(h1 jets)', 'deltaPhi(h2 jets)']]\n",
    "qcd = qcd_raw[['hh_mass', 'h1_mass', 'h2_mass', 'deltaR(h1, h2)', 'deltaR(h1 jets)', 'deltaR(h2 jets)', 'deltaPhi(h1, h2)', 'deltaPhi(h1 jets)', 'deltaPhi(h2 jets)']]\n",
    "\n",
    "# hh_all = hh_raw[['deltaR(h1 jets)', 'deltaR(h2 jets)']]\n",
    "# qcd = qcd_raw[['deltaR(h1 jets)', 'deltaR(h2 jets)']]\n",
    "\n",
    "# hh_all = hh_raw[['hh_mass', 'h1_mass', 'h2_mass']]\n",
    "# qcd = qcd_raw[['hh_mass', 'h1_mass', 'h2_mass']]\n",
    "\n",
    "n_factors = np.shape(hh_all)[1]\n",
    "print(n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.57863363e+02  1.48291836e+02  1.58296646e+02  2.17318000e+00\n",
      "   2.39941158e+00  3.04517197e+00 -1.39974523e+00  2.26137894e+00\n",
      "  -2.73688633e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 3.98807335e+02  9.65536398e+01  5.85546013e+01  3.02752724e+00\n",
      "   1.34373550e+00  1.11838980e+00 -2.62879683e+00  1.20060802e+00\n",
      "   1.10447589e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 5.17175766e+02  1.10271880e+02  1.30164227e+02  1.99348524e+00\n",
      "   6.97377344e-01  1.15238492e+00 -1.70520791e+00 -6.44060135e-01\n",
      "   1.15179259e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 7.03807212e+02  1.79640526e+02  1.66136193e+02  2.51804950e+00\n",
      "   2.05337635e+00  2.09055659e+00 -2.44151538e+00 -1.87211138e+00\n",
      "   1.42004728e+00  1.00000000e+00  0.00000000e+00]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "hh_all = np.array(hh_all)\n",
    "qcd = np.array(qcd)\n",
    "\n",
    "# add labels to di-higgs\n",
    "hh_all=hh_all[:,:n_factors]\n",
    "# # print(hh[0:3])\n",
    "hh_labels= np.zeros((len(hh_all),1))\n",
    "hh_labels = hh_labels+1\n",
    "#a = hh[:len(hh)]\n",
    "# print(a.shape)\n",
    "# hh_all[:,0] = np.random.rand(np.shape(hh_all)[0])\n",
    "hh_all = np.append(hh_all, hh_labels, axis=1)\n",
    "hh_all = np.append(hh_all, 1-hh_labels, axis=1)## hh qcd labels \n",
    "\n",
    "\n",
    "# print(hh.shape)\n",
    "# print(hh[0:3])\n",
    "\n",
    "# add labels to qcd\n",
    "qcd=qcd[:,:n_factors]\n",
    "# print(hh[0:3])\n",
    "qcd_labels= np.zeros((len(qcd),1))\n",
    "#a = hh[:len(hh)]\n",
    "# print(a.shape)\n",
    "# qcd hh labels \n",
    "# qcd[:, 0] = -1 * np.random.rand(np.shape(qcd)[0])\n",
    "qcd = np.append(qcd, qcd_labels, axis=1) \n",
    "qcd = np.append(qcd, 1-qcd_labels, axis=1)# qcd qcd labels\n",
    "\n",
    "\n",
    "# use this for dummy variables\n",
    "# hh_all[:,0] = np.random.rand(np.shape(hh_all)[0])\n",
    "# hh_all[:,1] = np.random.rand(np.shape(hh_all)[0])\n",
    "# qcd[:, 0] = -1 * np.random.rand(np.shape(qcd)[0]) # 0% overlap\n",
    "# qcd[:, 1] = -1 * np.random.rand(np.shape(qcd)[0])\n",
    "# qcd[:, 0] = hh_all[:len(qcd),0] # 100% overlap\n",
    "# qcd[:, 1] = hh_all[:len(qcd),1]\n",
    "# qcd[:, 0] = hh_all[:len(qcd),0] -.0625 # n% overlap\n",
    "# qcd[:, 1] = hh_all[:len(qcd),1] -.0625\n",
    "\n",
    "\n",
    "# select a quarter of hh events so that the set is half and half\n",
    "# we shuffle the list first to take a random 1/4. this means we have a different dataset every time\n",
    "# np.random.seed(0)\n",
    "# np.random.shuffle(hh_all) \n",
    "hh = hh_all[0:len(qcd)]\n",
    "# print(hh[:4])\n",
    "# print(qcd[:4])\n",
    "\n",
    "all_data = np.append(hh,qcd, axis=0) \n",
    "all_data[:n_factors,:]\n",
    "\n",
    "np.random.seed(0)\n",
    "# for i in range (4): # shuffle 4 times\n",
    "#     np.random.shuffle(all_data) \n",
    "print(all_data[:4])\n",
    "all_labels = all_data[:,n_factors:]\n",
    "# for testing model resilience\n",
    "# for i in range(2):\n",
    "#     np.random.shuffle(all_labels)\n",
    "all_data = all_data[:,:n_factors]\n",
    "# print(all_data[:4])\n",
    "print(all_labels[:4])\n",
    "# print(test_data)\n",
    "# print(len(all_data))\n",
    "# print(all_labels)\n",
    "\n",
    "input_size = n_factors       \n",
    "hidden_size = 500      # The number of nodes at the hidden layer\n",
    "num_classes = all_labels.shape[1]       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 5         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16314647  0.20528419  0.26390849  0.27974634  0.43658628  0.60794872\n",
      "  -0.44564699  0.71985814 -0.87118638]\n",
      " [ 0.18181244  0.13366168  0.09762087  0.38972366  0.24450015  0.22327923\n",
      "  -0.83694901  0.38218603  0.35156898]\n",
      " [ 0.23577547  0.15265219  0.21700677  0.25661482  0.12689168  0.23006613\n",
      "  -0.54289934 -0.20502178  0.3666305 ]\n",
      " [ 0.32085895  0.24868099  0.2769784   0.32414026  0.37362324  0.41736598\n",
      "  -0.77732286 -0.59594373  0.45201945]]\n"
     ]
    }
   ],
   "source": [
    "# scale the data by dividing it by the max value of each\n",
    "for i in range(np.shape(all_data)[1]):\n",
    "    all_data[:,i] = np.true_divide(all_data[:,i], np.max(all_data[:,i]))\n",
    "print(all_data[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD9CAYAAAC1DKAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE1VJREFUeJzt3X+QXWV9x/H3V1Kw4jQJmEljwkioqYEpU6E7SMuMP4AiUIekU9Q4VaKNk6pobWmnxvEPMnY61U4tlamDTUENrYPYqENasUxMYGxnJDUoIpBiFqySNJCVH+kPRxT99o/7LL0su9m999xfu8/7NbOz5zznued873Pv3s8959x7NjITSVJ9njfsAiRJw2EASFKlDABJqpQBIEmVMgAkqVIGgCRVatYAiIhPRMSRiLi3re2kiNgVEQfK76WlPSLi2ogYj4h7IuLstttsLP0PRMTG/twdSdJczWUP4FPAxVPatgC7M3MNsLvMA1wCrCk/m4HroBUYwNXAK4BzgKsnQ0OSNByzBkBmfgV4fErzOmB7md4OrG9rvzFb7gSWRMQK4LXArsx8PDOfAHbx3FCRJA1Qt+cAlmfm4TL9CLC8TK8EHm7rd7C0zdQuSRqSRU1XkJkZET27nkREbKZ1+IgTTzzxV9auXdurVUtSFe66667vZ+ay2fp1GwCPRsSKzDxcDvEcKe2HgFPa+q0qbYeAV09pv2O6FWfmNmAbwNjYWO7bt6/LEiWpThHx3bn06/YQ0E5g8pM8G4Fb2tqvKJ8GOhc4Wg4V3QZcFBFLy8nfi0qbJGlIZt0DiIibaL17f1FEHKT1aZ4PAZ+NiE3Ad4E3lO63ApcC48APgLcBZObjEfEnwNdKvw9m5tQTy5KkAYpRvhy0h4AkqXMRcVdmjs3Wz28CS1KlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZANIo2Lp42BWoQgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEkz2r/29GGXoD4yACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlGgVARPxBRNwXEfdGxE0R8fyIWB0ReyNiPCJujojjS98Tyvx4WX5qL+6AJKk7XQdARKwEfg8Yy8xfAo4DNgAfBq7JzJcCTwCbyk02AU+U9mtKP0nSkDQ9BLQI+NmIWAS8ADgMnA/sKMu3A+vL9LoyT1l+QUREw+1LkrrUdQBk5iHgL4Dv0XrhPwrcBTyZmU+XbgeBlWV6JfBwue3Tpf/J3W5fktRMk0NAS2m9q18NvBg4Ebi4aUERsTki9kXEvomJiaarkyTNoMkhoAuB72TmRGb+GPg8cB6wpBwSAlgFHCrTh4BTAMryxcBjU1eamdsycywzx5YtW9agPEnSsTQJgO8B50bEC8qx/AuA+4HbgctLn43ALWV6Z5mnLN+Tmdlg+5KkBpqcA9hL62Tu14FvlXVtA94HXBUR47SO8d9QbnIDcHJpvwrY0qBuSVJDi2bvMrPMvBq4ekrzQ8A50/T9IfD6JtuTJPWO3wSWpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBI6tj+tacPuwT1gAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIq1SgAImJJROyIiH+PiP0R8asRcVJE7IqIA+X30tI3IuLaiBiPiHsi4uze3AVJUjea7gF8FPjnzFwL/DKwH9gC7M7MNcDuMg9wCbCm/GwGrmu4bUlSA10HQEQsBl4J3ACQmT/KzCeBdcD20m07sL5MrwNuzJY7gSURsaLryiVJjTTZA1gNTACfjIhvRMT1EXEisDwzD5c+jwDLy/RK4OG22x8sbZKkIWgSAIuAs4HrMvMs4H/5/8M9AGRmAtnJSiNic0Tsi4h9ExMTDcqTJB1LkwA4CBzMzL1lfgetQHh08tBO+X2kLD8EnNJ2+1Wl7Vkyc1tmjmXm2LJlyxqUJ0k6lq4DIDMfAR6OiJeVpguA+4GdwMbSthG4pUzvBK4onwY6FzjadqhIkjRgixre/j3ApyPieOAh4G20QuWzEbEJ+C7whtL3VuBSYBz4QekrSRqSRgGQmXcDY9MsumCavglc2WR7UnW2LoatR4ddhRYovwksSZUyACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqpQBIEmVMgAkqVIGgCRVygCQpEoZAJJUKQNAkiplAEhSpQwASaqUASBJlTIAJKlSBoAkVcoAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJAGaeviYVcgPcMAkKRKGQCSVCkDQJIqZQBIUqUMAEmqlAEgSZUyACSpUo0DICKOi4hvRMQ/lfnVEbE3IsYj4uaIOL60n1Dmx8vyU5tuW5LUvV7sAbwX2N82/2Hgmsx8KfAEsKm0bwKeKO3XlH6SpCFpFAARsQr4DeD6Mh/A+cCO0mU7sL5MryvzlOUXlP6SpCFougfwV8AfAz8t8ycDT2bm02X+ILCyTK8EHgYoy4+W/pKkIeg6ACLidcCRzLyrh/UQEZsjYl9E7JuYmOjlqiVJbZrsAZwHXBYR/wF8htahn48CSyJiUemzCjhUpg8BpwCU5YuBx6auNDO3ZeZYZo4tW7asQXmSpGPpOgAy8/2ZuSozTwU2AHsy87eB24HLS7eNwC1lemeZpyzfk5nZ7fYlSc3043sA7wOuiohxWsf4byjtNwAnl/argC192LYkaY4Wzd5ldpl5B3BHmX4IOGeaPj8EXt+L7UmSmvObwJJUKQNAkiplAEjSCDm45V8Gti0DQJqP/N/C6gEDQJqnztx+5rBL0DxnAEhSpQwASaqUASBJlTIApH7wJK3mAQNAkiplAEhSpQwASaqUASBpqD72jj3DLqFaBoAkVcoAkNQz+9eePuwS1AEDQJIqZQBIUqUMAEmqlAEgSZUyACSpUgaAJA3BIP/z10wMAGkBOXXLF4ddguYRA0CSKmUASAuQl1fQXBgAklQpA0CSKmUASFKlDABpHvNYv5owAKQR8pE3vm7YJagiBoAkVcoAkBaYM7efOewSNE8YAJJUKQNAkiplAEjzwEI4ObwQ7sNC03UARMQpEXF7RNwfEfdFxHtL+0kRsSsiDpTfS0t7RMS1ETEeEfdExNm9uhOSpM412QN4GvjDzDwDOBe4MiLOALYAuzNzDbC7zANcAqwpP5uB6xpsu+9G4VKtUs38jkP/dR0AmXk4M79epv8b2A+sBNYB20u37cD6Mr0OuDFb7gSWRMSKriuXJDXSk3MAEXEqcBawF1iemYfLokeA5WV6JfBw280OljZJA+K76sEb5aMJjQMgIl4IfA74/cz8r/ZlmZlAdri+zRGxLyL2TUxMNC1PkjSDRgEQET9D68X/05n5+dL86OShnfL7SGk/BJzSdvNVpe1ZMnNbZo5l5tiyZcualCdpCPy0z/zR5FNAAdwA7M/Mv2xbtBPYWKY3Are0tV9RPg10LnC07VCRpD7yX0VqOk32AM4D3gKcHxF3l59LgQ8Bvx4RB4ALyzzArcBDwDjwt8C7GmxbmteG8S6520tE+I5+4VrU7Q0z81+BmGHxBdP0T+DKbrcnSeotvwksqatPB3WyZ7B/7ekdr1/9ZwBIUqUMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAHRrlCztJUicMAEmqlAEgSZUyACSpUgaAJFXKAJCkShkAklQpA0DS0HiV0OEyAHrE7wdImm8MAKli/qvIuhkAqsbuPb8w7BKkkVJ9AGzdunXYJWjIRi0YBv2c7PZ/BWv+qz4ApFHU71AatdDrRDf/vnIQ5uObSQOgzzw5rKbaPykzn1+455v5+ILeqWoCoIYHU/XqRzB4aGh6C+m1pJoAkEbN1BeSfnwmvttg8NNBdTAAemgh75736r51+u5ppv6DeBe2kB/PYfFxe7Zh12oAdGHYD1ov9Oo+jOJYjGJNGk0feePrerq++fbcMwCGaBSPJQ7rnX43RvWPbT4fPhnF5+RMOn3859N9GxQD4Bj6+QLjp4OebT79cc6nWvutm0N0oxbco/h4DmqMDABG7zPXvTpO3s221b1RfCHplWHet148h4f9hmtU/w4NAGnAvAKmRoUBMI/0cs9Ag7PgHoeti/uy2qbvkkf1G8KjzACQNGejfoJ72Id65hsDQJIqZQBUyHdJGjWdPif7/Rye6fsBvf7ewLAZAHrGqP0RSj7H+ssA0KxqDIZe3Idhf9pnpvvQafuc9enkcFOeHJ7ZwAMgIi6OiAciYjwitgx6+1rYagyrkdfDYPAKpb010ACIiOOAjwGXAGcAb4qIMwZZg9TE1MAY5AtS3965D8sxgmG+vdDP13MDg94DOAcYz8yHMvNHwGeAdQOuQRXq54vksA/1LDhd7DHMFBjHavdxG3wArAQebps/WNok6Zhm+g5Cr9ondRQMxwiradezdfG0oTSs71dEZg5uYxGXAxdn5tvL/FuAV2Tmu9v6bAY2l9mXAQ90ubkXAd9vUG6/WFfnRrU26+qMdXWu29pekpnLZuu0qIsVN3EIOKVtflVpe0ZmbgO2Nd1QROzLzLGm6+k16+rcqNZmXZ2xrs71u7ZBHwL6GrAmIlZHxPHABmDngGuQJDHgPYDMfDoi3g3cBhwHfCIz7xtkDZKklkEfAiIzbwVuHcCmGh9G6hPr6tyo1mZdnbGuzvW1toGeBJYkjQ4vBSFJlZrXARARr4+I+yLipxEx45nymS4/UU5G7y3tN5cT072o66SI2BURB8rvpdP0eU1E3N3288OIWF+WfSoivtO27OWDqqv0+0nbtne2tQ9zvF4eEV8tj/c9EfHGtmU9Ha/ZLlcSESeU+z9exuPUtmXvL+0PRMRrm9TRRV1XRcT9ZXx2R8RL2pZN+5gOsLa3RsREWw1vb1u2sTz2ByJi44Druqatpm9HxJNty/o2ZhHxiYg4EhH3zrA8IuLaUvc9EXF227LejVdmztsf4HRa3xW4Axiboc9xwIPAacDxwDeBM8qyzwIbyvTHgXf2qK4/B7aU6S3Ah2fpfxLwOPCCMv8p4PI+jNec6gL+Z4b2oY0X8IvAmjL9YuAwsKTX43Ws50tbn3cBHy/TG4Cby/QZpf8JwOqynuMGWNdr2p5D75ys61iP6QBreyvw19Pc9iTgofJ7aZleOqi6pvR/D60PpgxizF4JnA3cO8PyS4EvAQGcC+ztx3jN6z2AzNyfmbN9UWzay09ERADnAztKv+3A+h6Vtq6sb67rvRz4Umb+oEfbn0mndT1j2OOVmd/OzANl+j+BI8CsX3TpwlwuV9Je7w7ggjI+64DPZOZTmfkdYLysbyB1Zebtbc+hO2l9z2YQmlzi5bXArsx8PDOfAHYBFw+prjcBN/Vo28eUmV+h9aZvJuuAG7PlTmBJRKygx+M1rwNgjma6/MTJwJOZ+fSU9l5YnpmHy/QjwPJZ+m/guU+8Py27ftdExAkDruv5EbEvIu6cPCzFCI1XRJxD6x3dg23NvRqvuVyu5Jk+ZTyO0hqffl7qpNN1b6L1DnLSdI9pr8y1tt8qj9GOiJj8QuhIjFk5XLYaaL92dD/HbDYz1d7T8Rr4x0A7FRFfBn5+mkUfyMxbBl3PpGPV1T6TmRkRM37UqqT6mbS+GzHp/bReCI+n9TGw9wEfHGBdL8nMQxFxGrAnIr5F60Wuaz0er78DNmbmT0tz1+O1EEXEm4Ex4FVtzc95TDPzwenX0Bf/CNyUmU9FxO/S2oM6f4Dbn80GYEdm/qStbdhj1ncjHwCZeWHDVcx0+YnHaO1WLSrv4p5zWYpu64qIRyNiRWYeLi9YR46xqjcAX8jMH7ete/Ld8FMR8UngjwZZV2YeKr8fiog7gLOAzzHk8YqInwO+SCv872xbd9fjNY1ZL1fS1udgRCwCFtN6Ps3ltv2si4i4kFaoviozn5psn+Ex7dWL2Vwu8fJY2+z1tM77TN721VNue8eg6mqzAbiyvaHPYzabmWrv6XjVcAho2stPZOuMyu20jr8DbAR6tUexs6xvLut9znHH8iI4edx9PTDtJwX6UVdELJ08hBIRLwLOA+4f9niVx+4LtI6L7piyrJfjNZfLlbTXezmwp4zPTmBDtD4ltBpYA/xbg1o6qisizgL+BrgsM4+0tU/7mPaorrnWtqJt9jJgf5m+Dbio1LgUuIhn7w33ta5S21paJ1S/2tbW7zGbzU7givJpoHOBo+WNTm/Hqx9nuAf1A/wmrWNgTwGPAreV9hcDt7b1uxT4Nq30/kBb+2m0/kDHgX8ATuhRXScDu4EDwJeBk0r7GHB9W79TaSX686bcfg/wLVovZH8PvHBQdQG/Vrb9zfJ70yiMF/Bm4MfA3W0/L+/HeE33fKF1SOmyMv38cv/Hy3ic1nbbD5TbPQBc0uPn+2x1fbn8HUyOz87ZHtMB1vZnwH2lhtuBtW23/Z0yluPA2wZZV5nfCnxoyu36Oma03vQdLs/pg7TO2bwDeEdZHrT+edaDZftjbbft2Xj5TWBJqlQNh4AkSdMwACSpUgaAJFXKAJCkShkAklQpA0CSKmUASFKlDABJqtT/AVshQWKU7sLNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(all_data, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x103c4e898>\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(all_data, all_labels, train_size=0.3, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = torch.stack([torch.Tensor(i) for i in train_data])\n",
    "train_labels = torch.stack([torch.Tensor(i) for i in train_labels])\n",
    "test_data = torch.stack([torch.Tensor(i) for i in test_data])\n",
    "test_labels = torch.stack([torch.Tensor(i) for i in test_labels])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = utils.TensorDataset(train_data, train_labels)\n",
    "\n",
    "test_dataset = utils.TensorDataset(test_data, test_labels)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x11cf65ef0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = utils.DataLoader(train_dataset)\n",
    "\n",
    "test_loader = utils.DataLoader(test_dataset)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x11d06db40>\n",
      "0 [tensor([[ 0.3239,  0.4726,  0.5254,  0.2889,  0.5906,  0.6293,  0.6913, -0.9937,\n",
      "         -0.9703]]), tensor([[1., 0.]])]\n",
      "1 [tensor([[ 0.2442,  0.1496,  0.2398,  0.4023,  0.1998,  0.3372,  0.9316, -0.3328,\n",
      "         -0.5155]]), tensor([[0., 1.]])]\n",
      "2 [tensor([[ 0.2227,  0.1374,  0.1940,  0.3974,  0.1896,  0.2406, -0.9624, -0.2967,\n",
      "          0.3297]]), tensor([[1., 0.]])]\n",
      "3 [tensor([[ 0.2245,  0.3535,  0.3438,  0.3797,  0.6307,  0.6811, -0.9389, -0.8562,\n",
      "         -0.5508]]), tensor([[0., 1.]])]\n",
      "4 [tensor([[ 0.3722,  0.3576,  0.2657,  0.5108,  0.5276,  0.4398, -0.9080, -0.9216,\n",
      "          0.1880]]), tensor([[0., 1.]])]\n",
      "5 [tensor([[ 0.2251,  0.3276,  0.3842,  0.4373,  0.5811,  0.7800, -0.9923, -0.9717,\n",
      "          0.3890]]), tensor([[1., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "print(enumerate(train_loader))\n",
    "for i, e in enumerate(train_loader):\n",
    "    print(i, e)\n",
    "    if(i>4):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "#         self.relu = nn.Softmax(dim=None)                          # Non-Linear ReLU Layer: max(0,x)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "        self.pred = torch.Tensor()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        self.pred = out\n",
    "#         print(out.type)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.cuda()    # You can comment out this line to disable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SHAPE: torch.Size([1, 9])\n",
      "OUTPUT SHAPE: torch.Size([1, 2])\n",
      "Epoch [1/5], Step [100/10], Loss: 0.8743\n",
      "Epoch [1/5], Step [200/10], Loss: 1.0201\n",
      "Epoch [1/5], Step [300/10], Loss: 0.7987\n",
      "Epoch [1/5], Step [400/10], Loss: 0.8912\n",
      "Epoch [1/5], Step [500/10], Loss: 0.6585\n",
      "Epoch [1/5], Step [600/10], Loss: 0.5245\n",
      "Epoch [1/5], Step [700/10], Loss: 0.6891\n",
      "Epoch [1/5], Step [800/10], Loss: 0.6888\n",
      "Epoch [1/5], Step [900/10], Loss: 0.8191\n",
      "Epoch [1/5], Step [1000/10], Loss: 0.6376\n",
      "DATA SHAPE: torch.Size([1, 9])\n",
      "OUTPUT SHAPE: torch.Size([1, 2])\n",
      "Epoch [2/5], Step [100/10], Loss: 0.9314\n",
      "Epoch [2/5], Step [200/10], Loss: 0.8961\n",
      "Epoch [2/5], Step [300/10], Loss: 0.8951\n",
      "Epoch [2/5], Step [400/10], Loss: 0.8260\n",
      "Epoch [2/5], Step [500/10], Loss: 0.6392\n",
      "Epoch [2/5], Step [600/10], Loss: 0.5406\n",
      "Epoch [2/5], Step [700/10], Loss: 0.7785\n",
      "Epoch [2/5], Step [800/10], Loss: 0.8376\n",
      "Epoch [2/5], Step [900/10], Loss: 0.7966\n",
      "Epoch [2/5], Step [1000/10], Loss: 0.7638\n",
      "DATA SHAPE: torch.Size([1, 9])\n",
      "OUTPUT SHAPE: torch.Size([1, 2])\n",
      "Epoch [3/5], Step [100/10], Loss: 0.8833\n",
      "Epoch [3/5], Step [200/10], Loss: 0.8467\n",
      "Epoch [3/5], Step [300/10], Loss: 0.8992\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        data = Variable(data)       # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        if(i==0):\n",
    "            print(\"DATA SHAPE:\", data.shape)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(data)                             # Forward pass: compute the output class given a image\n",
    "        if(i==0):\n",
    "            print(\"OUTPUT SHAPE:\", outputs.shape)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, torch.max(labels, 1)[1])                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "#             print(\"SMH\")\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)/batch_size, loss.data.item()))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0.00\n",
    "total = 0.00\n",
    "preds_h = [] # all hh prob\n",
    "preds_q = [] # all qcd prob\n",
    "hh_pred = [] # hh prob for hh events\n",
    "hh_pred_wrong = []\n",
    "qcd_pred = [] # qcd prob for qcd events\n",
    "qcd_pred_wrong = []\n",
    "for data, labels in test_loader:\n",
    "    data = Variable(data)\n",
    "    outputs = net(data)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    \n",
    "#     np.append(preds, outputs[0].data.numpy())\n",
    "    preds_h.append(outputs.data[0][0].data)\n",
    "    preds_q.append(outputs.data[0][1].data)\n",
    "    if(labels[0][0].data==1): # if higgs\n",
    "        hh_pred.append(max(outputs.data[0]))\n",
    "        if(outputs.data[0][0].data<outputs.data[0][1].data):\n",
    "            hh_pred_wrong.append(outputs.data[0][1].data)\n",
    "    else:\n",
    "        qcd_pred.append(max(outputs.data[0]))\n",
    "        if(outputs.data[0][0].data>outputs.data[0][1].data):\n",
    "            qcd_pred_wrong.append(outputs.data[0][0].data)\n",
    "\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    labels = labels.long()\n",
    "#     print((labels, 1)[1])\n",
    "    correct += (predicted == torch.max(labels, 1)[1]).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * np.float(correct) / np.float(total)))\n",
    "print(\"correct:\", correct.item())\n",
    "print(\"total:\", total)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(x < 0 for x in hh_pred).item(), \"DiHiggs events with prob less than 0\")\n",
    "print(sum(x > 1 for x in hh_pred).item(), \"DiHiggs events with prob greater than 1\")\n",
    "print(sum(y < 0 for y in qcd_pred).item(), \"QCD events with prob less than 0\")\n",
    "print(sum(y > 1 for y in qcd_pred).item(), \"QCD events with prob greater than 1\")\n",
    "\n",
    "plt.hist(hh_pred, bins=np.linspace(0, 2, 100), alpha=0.375, label=\"higgs\", density=1)\n",
    "plt.hist(qcd_pred, bins=np.linspace(0, 2, 100), alpha=0.375, label=\"qcd\", density=1)\n",
    "plt.legend()\n",
    "plt.title(\"Event Classification Score for QCD and DiHiggs\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Relative Frequency\")\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Incorrect event classification score for QCD and DiHiggs\")\n",
    "plt.hist(hh_pred_wrong, bins=np.linspace(0, 2, 100), alpha=0.375, label=\"higgs\", density=1)\n",
    "plt.hist(qcd_pred_wrong, bins=np.linspace(0, 2, 100), alpha=0.375, label=\"qcd\", density=1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_cmap = plt.cm.jet\n",
    "# my_cmap.set_under('w',1)\n",
    "\n",
    "plt.hist2d(preds_h, preds_q, 20, label=\"Frequency\")\n",
    "plt.xlabel(\"DiHiggs Probability\")\n",
    "plt.ylabel(\"QCD Probability\")\n",
    "plt.title(\"Frequency of QCD vs DiHiggs Probabilities\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# #\n",
    "# # Create an X-Y mesh of the same dimension as the 2D data. You can\n",
    "# # think of this as the floor of the plot.\n",
    "# #\n",
    "# x_data, y_data = np.meshgrid( preds_q,\n",
    "#                               preds_h )\n",
    "# #\n",
    "# # Flatten out the arrays so that they may be passed to \"ax.bar3d\".\n",
    "# # Basically, ax.bar3d expects three one-dimensional arrays:\n",
    "# # x_data, y_data, z_data. The following call boils down to picking\n",
    "# # one entry from each array and plotting a bar to from\n",
    "# # (x_data[i], y_data[i], 0) to (x_data[i], y_data[i], z_data[i]).\n",
    "# #\n",
    "# x_data = x_data.flatten()\n",
    "# y_data = y_data.flatten()\n",
    "# z_data = data_array.flatten()\n",
    "# ax.bar3d( x_data,\n",
    "#           y_data,\n",
    "#           np.zeros(len(z_data)),\n",
    "#           1, 1, z_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulerspython",
   "language": "python",
   "name": "eulerspython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
